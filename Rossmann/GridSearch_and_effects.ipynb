{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d224fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns  #Visualization\n",
    "from pylab import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "import math\n",
    "import matplotlib\n",
    "\n",
    "\n",
    "import pandas as pd   #preprocessing\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "import torch          #modelling\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from collections import defaultdict\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from IMV_LSTM import IMVTensorLSTM\n",
    "from IMV_LSTM import IMVFullLSTM\n",
    "\n",
    "from boruta import BorutaPy\n",
    "from BorutaShap import BorutaShap\n",
    "\n",
    "import shap\n",
    "import shap.plots\n",
    "\n",
    "import operator\n",
    "\n",
    "import time\n",
    "\n",
    "import os\n",
    "from IPython.utils import io\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", \".*does not have many workers.*\")\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning) \n",
    "\n",
    "\n",
    "def mean_absolute_scaled_error(y_true, y_pred, y_train):\n",
    "    e_t = y_true - y_pred\n",
    "    scale = mean_absolute_error(y_train[1:], y_train[:-1])\n",
    "    return np.mean(np.abs(e_t / scale))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c86e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "\n",
    "sns.set(style='whitegrid',palette='muted',font_scale=1.2)\n",
    "\n",
    "#HAPPY_COLORS_PALETTE = ['#01BEFE','#FFDD00','#FF7D00','#FF006D','#ADFF02','#8F00FF']\n",
    "\n",
    "#sns.set_palette(sns.color_palette(HAPPY_COLORS_PALETTE))\n",
    "\n",
    "rcParams['figure.figsize']=12,8\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35bd7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EPOCHS = 1001\n",
    "BATCH_SIZE = 7\n",
    "SEQUENCE_LENGTH = 15\n",
    "#N_HIDDEN = 32\n",
    "N_LAYERS = 1\n",
    "PATIENCE = 50\n",
    "LEARNING = 0.005\n",
    "\n",
    "TGT = 'Sales'\n",
    "\n",
    "univariate = True\n",
    "all_features = True\n",
    "\n",
    "corr_train = True\n",
    "\n",
    "Boruta_GB = True\n",
    "Boruta_RF = True\n",
    "\n",
    "Boruta_SHAPGB = True\n",
    "Boruta_SHAPRF = True\n",
    "\n",
    "LIME_train = True\n",
    "\n",
    "SHAP_insta = True\n",
    "SHAP_avrag = True \n",
    "\n",
    "IMV_Tens = True \n",
    "IMV_Full = True "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87417b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(8)\n",
    "np.random.seed(8)\n",
    "pl.seed_everything(8);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5886af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_dataframe(df, corr):\n",
    "    rows = []\n",
    "    '''\n",
    "    ['rec_id', 'Date', 'year', 'month', 'temp', 'atemp', 'humidity', 'windspeed', TGT,\n",
    "    'season_1', 'season_2', 'season_3', 'season_4', 'is_workingday_0', 'is_workingday_1', 'is_holiday_0',\n",
    "    'is_holiday_1', 'weather_condition_1', 'weather_condition_2', 'weather_condition_3', 'weekday_0',\n",
    "    'weekday_1', 'weekday_2', 'weekday_3', 'weekday_4', 'weekday_5', 'weekday_6', 'day']\n",
    "    \n",
    "    '''\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        row_data = dict(\n",
    "            Sales = row.Sales,\n",
    "        )\n",
    "        for column in corr:\n",
    "            row_data[column] = row[column]\n",
    "            \n",
    "        rows.append(row_data)\n",
    "    \n",
    "    features_df = pd.DataFrame(rows)\n",
    "\n",
    "    return features_df\n",
    "\n",
    "#spliits the data in test and train\n",
    "def train_test_spliter(ratio,features_df ):\n",
    "    train_size = int(len(features_df)-ratio)\n",
    "    train_df, test_df = features_df[:train_size], features_df[train_size + 1:]\n",
    "\n",
    "    return train_df, test_df, train_size\n",
    "\n",
    "def data_scaler(train_df,test_df):\n",
    "    scaler = MinMaxScaler(feature_range=(-1,1))\n",
    "    scaler = scaler.fit(train_df)\n",
    "\n",
    "    train_df = pd.DataFrame(\n",
    "        scaler.transform(train_df),\n",
    "        index = train_df.index,\n",
    "        columns = train_df.columns\n",
    "        )\n",
    "\n",
    "    test_df = pd.DataFrame(\n",
    "        scaler.transform(test_df),\n",
    "        index = test_df.index,\n",
    "        columns = test_df.columns\n",
    "        )\n",
    "    \n",
    "    return train_df, test_df, scaler\n",
    "\n",
    "\n",
    "def create_sequences (input_data:pd.DataFrame, target_column, sequence_length):\n",
    "    sequences = []\n",
    "    data_size = len(input_data)\n",
    "\n",
    "    for i in (range(data_size - sequence_length)):\n",
    "\n",
    "        sequence = input_data[i:i+sequence_length]\n",
    "\n",
    "        label_position = i + sequence_length\n",
    "        label = input_data.iloc[label_position][target_column]\n",
    "\n",
    "        sequences.append((sequence,label))\n",
    "    \n",
    "    return sequences\n",
    "\n",
    "def descale(descaler, values):\n",
    "    values_2d=np.array(values)[:,np.newaxis]\n",
    "    \n",
    "    return descaler.inverse_transform(values_2d).flatten()\n",
    "\n",
    "class Dataset(Dataset):\n",
    "\n",
    "    def __init__(self,sequences):\n",
    "        self.sequences = sequences\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        sequence, label = self.sequences[idx]\n",
    "\n",
    "        return dict(\n",
    "            sequence = torch.Tensor(sequence.to_numpy()),\n",
    "            label = torch.tensor(label).float()\n",
    "        )\n",
    "\n",
    "class SalesDataModule(pl.LightningDataModule):\n",
    "\n",
    "    def __init__(self, train_seqeunces,test_sequences, batch_size=8):\n",
    "        super().__init__()\n",
    "        self.train_sequences = train_sequences\n",
    "        self.test_sequences = test_sequences\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def setup(self,stage=None):\n",
    "        self.train_dataset = Dataset(self.train_sequences)\n",
    "        self.test_dataset = Dataset(self.test_sequences)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.train_dataset,\n",
    "            batch_size = self.batch_size,\n",
    "            shuffle = False,\n",
    "            num_workers = 0\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.test_dataset,\n",
    "            batch_size = 1,\n",
    "            shuffle = False,\n",
    "            num_workers = 0\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d58c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_values = [32]\n",
    "Rossmann_df = pd.read_csv('Rossmann_treated.csv')\n",
    "Rossmann_df = Rossmann_df[Rossmann_df['Store'] == 266]\n",
    "Rossmann_df.drop(columns = 'Customers', inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b545db",
   "metadata": {},
   "source": [
    "## Univariate treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3c9408",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "univariate = True\n",
    "if univariate == True:\n",
    "    folder_path = 'Predictions/grid_search_uni'\n",
    "    try:\n",
    "        os.mkdir(f'{folder_path}')\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    for N_HIDDEN in hidden_values:\n",
    "        torch.manual_seed(8)\n",
    "        np.random.seed(8)\n",
    "        pl.seed_everything(8);\n",
    "        iteration_start = time.monotonic()\n",
    "        class SalesPredictionModel(nn.Module):\n",
    "            def __init__(self, n_features, n_hidden = N_HIDDEN, n_layers = N_LAYERS):\n",
    "                super().__init__()\n",
    "                self.n_hidden = n_hidden\n",
    "\n",
    "                self.lstm = nn.LSTM(\n",
    "                    input_size = n_features,\n",
    "                    hidden_size = n_hidden,\n",
    "                    batch_first = True,\n",
    "                    num_layers = n_layers,\n",
    "                    dropout = 0.2\n",
    "                )\n",
    "                self.regressor = nn.Linear(n_hidden,1)\n",
    "\n",
    "            def forward(self,x):\n",
    "                self.lstm.flatten_parameters()\n",
    "\n",
    "                _, (hidden, _) = self.lstm(x)\n",
    "                out = hidden[-1]\n",
    "\n",
    "                return self.regressor(out)\n",
    "\n",
    "\n",
    "        class SalesPredictor(pl.LightningModule):\n",
    "\n",
    "            def __init__(self, n_features: int):\n",
    "                super().__init__()\n",
    "                self.model=SalesPredictionModel(n_features)\n",
    "                self.criterion = nn.MSELoss()\n",
    "\n",
    "            def forward(self, x, labels= None):\n",
    "                output = self.model(x)\n",
    "                loss = 0\n",
    "                if labels is not None:\n",
    "                    loss = self.criterion(output, labels.unsqueeze(dim=1))\n",
    "                return loss, output\n",
    "\n",
    "            def training_step(self, batch, batch_index):\n",
    "                sequences = batch['sequence']\n",
    "                labels = batch['label']\n",
    "\n",
    "                loss, outputs = self(sequences, labels)\n",
    "                self.log('train_loss', loss, prog_bar = True, logger=False)\n",
    "                return loss\n",
    "\n",
    "            def validation_step(self, batch, batch_index):\n",
    "                sequences = batch['sequence']\n",
    "                labels = batch['label']\n",
    "\n",
    "                loss, outputs = self(sequences, labels)\n",
    "                self.log('val_loss', loss, prog_bar = True, logger=False)\n",
    "                return loss\n",
    "\n",
    "            def test_step(self, batch, batch_index):\n",
    "                sequences = batch['sequence']\n",
    "                labels = batch['label']\n",
    "\n",
    "                loss, outputs = self(sequences, labels)\n",
    "                self.log('test_loss', loss, prog_bar = True, logger=False)\n",
    "                return loss\n",
    "\n",
    "            def configure_optimizers(self):\n",
    "                return optim.AdamW(self.parameters(), lr = LEARNING)\n",
    "\n",
    "\n",
    "        #makes SHAP calculations for all stores inside the rossmann_treated dataset if removed the [:1]\n",
    "\n",
    "        #to omit outputs\n",
    "        #with io.capture_output() as captured:\n",
    "        df = Rossmann_df.drop(columns  = 'Date')\n",
    "        sales_dependencies = {}\n",
    "        dic = {}\n",
    "\n",
    "        #return all columns names ('features') except for customers, since it's not an available \n",
    "        #information for future points\n",
    "        features_df = features_dataframe(df,[TGT]) \n",
    "        #returns dataframe with the features to be analised\n",
    "\n",
    "        #split into test and train and minmaxscaler\n",
    "        train_df, test_df, train_size =  train_test_spliter(105,features_df)\n",
    "        train_df, test_df, scaler = data_scaler(train_df,test_df)\n",
    "        #make sequences with the data\n",
    "        train_sequences = create_sequences(train_df,TGT,SEQUENCE_LENGTH)\n",
    "        test_sequences = create_sequences (test_df,TGT,SEQUENCE_LENGTH)\n",
    "\n",
    "        #trains the model and store the most recent checkpoints removing previous ones if existing\n",
    "        data_module = SalesDataModule(train_sequences, test_sequences, batch_size = BATCH_SIZE)\n",
    "        data_module.setup()\n",
    "        train_dataset = Dataset(train_sequences)\n",
    "        test_dataset = Dataset(test_sequences)\n",
    "        model = SalesPredictor(n_features = train_df.shape[1])\n",
    "\n",
    "\n",
    "\n",
    "        try:\n",
    "            os.remove(f\"{folder_path}/Checkpoints/Rossmann_LSTM_hidden{N_HIDDEN}.ckpt\")\n",
    "            #pass\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        checkpoint_callback = ModelCheckpoint(\n",
    "            dirpath = f'{folder_path}/Checkpoints',\n",
    "            filename = f'Rossmann_LSTM_hidden{N_HIDDEN}',\n",
    "            save_top_k = 1,\n",
    "            verbose = False ,\n",
    "            monitor = 'val_loss',\n",
    "            mode = 'min'\n",
    "        )\n",
    "        logger = TensorBoardLogger('lightning_logs', name = 'btc-price')\n",
    "        early_stopping_callback = EarlyStopping(monitor= 'val_loss', patience = PATIENCE)\n",
    "        trainer = pl.Trainer(\n",
    "            logger = logger,\n",
    "            callbacks=[early_stopping_callback, checkpoint_callback],\n",
    "            max_epochs = N_EPOCHS,\n",
    "            gpus = 0,\n",
    "        )\n",
    "        trainer.fit(model, data_module)\n",
    "\n",
    "        #load the best model from checkpoint\n",
    "        trained_model = SalesPredictor.load_from_checkpoint(\n",
    "        f'{folder_path}/Checkpoints/Rossmann_LSTM_hidden{N_HIDDEN}.ckpt',\n",
    "        n_features = train_df.shape[1]\n",
    "        )\n",
    "\n",
    "        predictions = []\n",
    "        labels = []\n",
    "\n",
    "        for item in test_dataset:\n",
    "            sequence = item['sequence']\n",
    "            label = item['label']\n",
    "\n",
    "            if len(predictions) > SEQUENCE_LENGTH:\n",
    "                for j in range(SEQUENCE_LENGTH):\n",
    "                    sequence[-SEQUENCE_LENGTH+j,0] = float(predictions[-SEQUENCE_LENGTH+j])\n",
    "            else: \n",
    "                for j in range(len(predictions)):\n",
    "                    sequence[-len(predictions)+j,0] = float(predictions[-len(predictions)+j])\n",
    "\n",
    "            _,output = trained_model(sequence.unsqueeze(dim=0))\n",
    "            predictions.append(output.item())\n",
    "            labels.append(label.item())\n",
    "\n",
    "\n",
    "        descaler = MinMaxScaler()\n",
    "        descaler.min_, descaler.scale_ = scaler.min_[0], scaler.scale_[0]\n",
    "\n",
    "        predictions_descaled = descale(descaler,predictions)\n",
    "        labels_descaled = descale(descaler,labels)\n",
    "\n",
    "        test_data = df[train_size+1:]\n",
    "        test_sequences_data = test_data.iloc[SEQUENCE_LENGTH:]\n",
    "\n",
    "        dates = matplotlib.dates.date2num(Rossmann_df.Date.iloc[-len(predictions_descaled):])\n",
    "        full_dates = matplotlib.dates.date2num(Rossmann_df.Date.tolist())\n",
    "\n",
    "        predictions_descaled = np.where(predictions_descaled<0, 0, predictions_descaled)\n",
    "\n",
    "        dic= {}\n",
    "        dic[f'store_pred_{N_HIDDEN}'] = predictions_descaled\n",
    "        pred_df = pd.DataFrame.from_dict(dic)\n",
    "        pred_df = pred_df.shift(-1)\n",
    "\n",
    "\n",
    "        dic = {}\n",
    "        dic[f'store_pred_dates'] = dates\n",
    "        dic[f'store_truth'] = Rossmann_df[TGT].iloc[-len(pred_df):]\n",
    "        truth_df = pd.DataFrame.from_dict(dic)\n",
    "\n",
    "\n",
    "        if N_HIDDEN != hidden_values[0]:\n",
    "            predictions_df = predictions_df.join(pred_df, how = 'left')\n",
    "        else:\n",
    "            truth_df.reset_index(inplace = True)\n",
    "            truth_df.drop('index', axis=1)\n",
    "            predictions_df = truth_df\n",
    "            predictions_df = predictions_df.join(pred_df, how = 'left')\n",
    "            predictions_df = predictions_df.iloc[:-1]\n",
    "\n",
    "        display(predictions_df)\n",
    "\n",
    "        dic = {}\n",
    "        dic[f'store_truth'] = Rossmann_df[TGT]\n",
    "        dic[f'store_truth_dates'] = full_dates\n",
    "        truth_df = pd.DataFrame.from_dict(dic)\n",
    "\n",
    "        dic= {}\n",
    "        dic[f'store_pred'] = predictions_descaled\n",
    "        dic[f'store_pred_dates'] = dates\n",
    "        prediction_df = pd.DataFrame.from_dict(dic)\n",
    "        prediction_df['store_pred'] =prediction_df['store_pred'].shift(-1)\n",
    "        \n",
    "        plt.figure(figsize=(21, 7))\n",
    "        plt.plot_date(truth_df.iloc[-2*len(prediction_df):,1],truth_df.iloc[-2*len(prediction_df):,0],'-', label='Truth')\n",
    "        plt.plot_date(prediction_df.iloc[:,1],prediction_df.iloc[:,0],'-',label ='Prediction')\n",
    "        plt.legend()\n",
    "        plt.show();\n",
    "\n",
    "        print('mean absolute scaled error: ')\n",
    "        print(mean_absolute_scaled_error(predictions_df['store_truth'].iloc[-(len(prediction_df)+1):],\n",
    "                                         predictions_df[f'store_pred_{N_HIDDEN}'],\n",
    "                                         truth_df.iloc[:-len(prediction_df),0]))\n",
    "        print('\\n','mean squared error: ')\n",
    "        print(mean_squared_error(predictions_df['store_truth'].iloc[-(len(prediction_df)+1):],\n",
    "                                         predictions_df[f'store_pred_{N_HIDDEN}']))\n",
    "        print('\\n','root mean squared error: ')\n",
    "        print((mean_squared_error(predictions_df['store_truth'].iloc[-(len(prediction_df)+1):],\n",
    "                                         predictions_df[f'store_pred_{N_HIDDEN}']))**(1/2)) \n",
    "        iteration_end = time.monotonic()\n",
    "        print('\\n',\"Iteration time: \", iteration_end - iteration_start)\n",
    "    predictions_df.to_csv(f'{folder_path}/Rossmann_LSTM_hidden{N_HIDDEN}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3168a870",
   "metadata": {},
   "source": [
    "## Multivariate treatment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ed76a6",
   "metadata": {},
   "source": [
    "#### All features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7862bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "if all_features == True:\n",
    "\n",
    "    folder_path = 'Predictions/grid_search_allfeatures'\n",
    "\n",
    "    try:\n",
    "        os.mkdir(f'{folder_path}')\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    mean_abs_allf = []\n",
    "    mean_sqr_allf = []\n",
    "    time_allf = []\n",
    "\n",
    "    for N_HIDDEN in hidden_values:        \n",
    "        torch.manual_seed(8)\n",
    "        np.random.seed(8)\n",
    "        pl.seed_everything(8);\n",
    "        \n",
    "        iteration_start = time.monotonic()\n",
    "        class SalesPredictionModel(nn.Module):\n",
    "            def __init__(self, n_features, n_hidden = N_HIDDEN, n_layers = N_LAYERS):\n",
    "                super().__init__()\n",
    "                self.n_hidden = n_hidden\n",
    "\n",
    "                self.lstm = nn.LSTM(\n",
    "                    input_size = n_features,\n",
    "                    hidden_size = n_hidden,\n",
    "                    batch_first = True,\n",
    "                    num_layers = n_layers,\n",
    "                    dropout = 0.2\n",
    "                )\n",
    "                self.regressor = nn.Linear(n_hidden,1)\n",
    "\n",
    "            def forward(self,x):\n",
    "                self.lstm.flatten_parameters()\n",
    "\n",
    "                _, (hidden, _) = self.lstm(x)\n",
    "                out = hidden[-1]\n",
    "\n",
    "                return self.regressor(out)\n",
    "\n",
    "\n",
    "        class SalesPredictor(pl.LightningModule):\n",
    "\n",
    "            def __init__(self, n_features: int):\n",
    "                super().__init__()\n",
    "                self.model=SalesPredictionModel(n_features)\n",
    "                self.criterion = nn.MSELoss()\n",
    "\n",
    "            def forward(self, x, labels= None):\n",
    "                output = self.model(x)\n",
    "                loss = 0\n",
    "                if labels is not None:\n",
    "                    loss = self.criterion(output, labels.unsqueeze(dim=1))\n",
    "                return loss, output\n",
    "\n",
    "            def training_step(self, batch, batch_index):\n",
    "                sequences = batch['sequence']\n",
    "                labels = batch['label']\n",
    "\n",
    "                loss, outputs = self(sequences, labels)\n",
    "                self.log('train_loss', loss, prog_bar = True, logger=False)\n",
    "                return loss\n",
    "\n",
    "            def validation_step(self, batch, batch_index):\n",
    "                sequences = batch['sequence']\n",
    "                labels = batch['label']\n",
    "\n",
    "                loss, outputs = self(sequences, labels)\n",
    "                self.log('val_loss', loss, prog_bar = True, logger=False)\n",
    "                return loss\n",
    "\n",
    "            def test_step(self, batch, batch_index):\n",
    "                sequences = batch['sequence']\n",
    "                labels = batch['label']\n",
    "\n",
    "                loss, outputs = self(sequences, labels)\n",
    "                self.log('test_loss', loss, prog_bar = True, logger=False)\n",
    "                return loss\n",
    "\n",
    "            def configure_optimizers(self):\n",
    "                return optim.AdamW(self.parameters(), lr = LEARNING)\n",
    "\n",
    "\n",
    "        #makes SHAP calculations for all stores inside the rossmann_treated dataset if removed the [:1]\n",
    "\n",
    "        #to omit outputs\n",
    "        #with io.capture_output() as captured:\n",
    "        df = Rossmann_df.drop(columns  = 'Date')\n",
    "        sales_dependencies = {}\n",
    "        dic = {}\n",
    "\n",
    "        #return all columns names ('features') except for customers, since it's not an available \n",
    "        #information for future points\n",
    "        features_df = features_dataframe(df,list(df.columns)) \n",
    "        #returns dataframe with the features to be analised\n",
    "\n",
    "        #split into test and train and minmaxscaler\n",
    "        train_df, test_df, train_size =  train_test_spliter(105,features_df)\n",
    "        train_df, test_df, scaler = data_scaler(train_df,test_df)\n",
    "        #make sequences with the data\n",
    "        train_sequences = create_sequences(train_df,TGT,SEQUENCE_LENGTH)\n",
    "        test_sequences = create_sequences (test_df,TGT,SEQUENCE_LENGTH)\n",
    "\n",
    "        #trains the model and store the most recent checkpoints removing previous ones if existing\n",
    "        data_module = SalesDataModule(train_sequences, test_sequences, batch_size = BATCH_SIZE)\n",
    "        data_module.setup()\n",
    "        train_dataset = Dataset(train_sequences)\n",
    "        test_dataset = Dataset(test_sequences)\n",
    "        model = SalesPredictor(n_features = train_df.shape[1])\n",
    "\n",
    "\n",
    "\n",
    "        try:\n",
    "            os.remove(f\"{folder_path}/Checkpoints/Rossmann_LSTM_hidden{N_HIDDEN}.ckpt\")\n",
    "            #pass\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        checkpoint_callback = ModelCheckpoint(\n",
    "            dirpath = f'{folder_path}/Checkpoints',\n",
    "            filename = f'Rossmann_LSTM_hidden{N_HIDDEN}',\n",
    "            save_top_k = 1,\n",
    "            verbose = False ,\n",
    "            monitor = 'val_loss',\n",
    "            mode = 'min'\n",
    "        )\n",
    "        logger = TensorBoardLogger('lightning_logs', name = 'btc-price')\n",
    "        early_stopping_callback = EarlyStopping(monitor= 'val_loss', patience = PATIENCE)\n",
    "        trainer = pl.Trainer(\n",
    "            logger = logger,\n",
    "            callbacks=[early_stopping_callback, checkpoint_callback],\n",
    "            max_epochs = N_EPOCHS,\n",
    "            gpus = 0,\n",
    "        )\n",
    "        trainer.fit(model, data_module)\n",
    "\n",
    "        #load the best model from checkpoint\n",
    "        trained_model = SalesPredictor.load_from_checkpoint(\n",
    "        f'{folder_path}/Checkpoints/Rossmann_LSTM_hidden{N_HIDDEN}.ckpt',\n",
    "        n_features = train_df.shape[1]\n",
    "        )\n",
    "\n",
    "        predictions = []\n",
    "        labels = []\n",
    "\n",
    "        for item in test_dataset:\n",
    "            sequence = item['sequence']\n",
    "            label = item['label']\n",
    "\n",
    "            if len(predictions) > SEQUENCE_LENGTH:\n",
    "                for j in range(SEQUENCE_LENGTH):\n",
    "                    sequence[-SEQUENCE_LENGTH+j,0] = float(predictions[-SEQUENCE_LENGTH+j])\n",
    "            else: \n",
    "                for j in range(len(predictions)):\n",
    "                    sequence[-len(predictions)+j,0] = float(predictions[-len(predictions)+j])\n",
    "\n",
    "            _,output = trained_model(sequence.unsqueeze(dim=0))\n",
    "            predictions.append(output.item())\n",
    "            labels.append(label.item())\n",
    "\n",
    "\n",
    "\n",
    "        descaler = MinMaxScaler()\n",
    "        descaler.min_, descaler.scale_ = scaler.min_[0], scaler.scale_[0]\n",
    "\n",
    "        predictions_descaled = descale(descaler,predictions)\n",
    "        labels_descaled = descale(descaler,labels)\n",
    "\n",
    "        test_data = df[train_size+1:]\n",
    "        test_sequences_data = test_data.iloc[SEQUENCE_LENGTH:]\n",
    "\n",
    "        dates = matplotlib.dates.date2num(Rossmann_df.iloc[-len(predictions_descaled):].Date.tolist())\n",
    "        full_dates = matplotlib.dates.date2num(Rossmann_df.Date.tolist())\n",
    "\n",
    "        predictions_descaled = np.where(predictions_descaled<0, 0, predictions_descaled)\n",
    "\n",
    "        dic= {}\n",
    "        dic[f'store_pred_{N_HIDDEN}'] = predictions_descaled\n",
    "        pred_df = pd.DataFrame.from_dict(dic)\n",
    "        pred_df = pred_df.shift(-1)\n",
    "\n",
    "\n",
    "        dic = {}\n",
    "        dic[f'store_pred_dates'] = dates\n",
    "        dic[f'store_truth'] = Rossmann_df[TGT].iloc[-len(pred_df):]\n",
    "        truth_df = pd.DataFrame.from_dict(dic)\n",
    "\n",
    "\n",
    "        if N_HIDDEN != hidden_values[0]:\n",
    "            predictions_df = predictions_df.join(pred_df, how = 'left')\n",
    "        else:\n",
    "            truth_df.reset_index(inplace = True)\n",
    "            truth_df.drop('index', axis=1)\n",
    "            predictions_df = truth_df\n",
    "            predictions_df = predictions_df.join(pred_df, how = 'left')\n",
    "            predictions_df = predictions_df.iloc[:-1]\n",
    "\n",
    "        #display(predictions_df)\n",
    "        \n",
    "        dic = {}\n",
    "        dic[f'store_truth'] = Rossmann_df[TGT]\n",
    "        dic[f'store_truth_dates'] = full_dates\n",
    "        truth_df = pd.DataFrame.from_dict(dic)\n",
    "\n",
    "        dic= {}\n",
    "        dic[f'store_pred'] = predictions_descaled\n",
    "        dic[f'store_pred_dates'] = dates\n",
    "        prediction_df = pd.DataFrame.from_dict(dic)\n",
    "        prediction_df['store_pred'] =prediction_df['store_pred'].shift(-1)\n",
    "        \n",
    "        plt.figure(figsize=(21, 7))\n",
    "        plt.plot_date(truth_df.iloc[-3*len(prediction_df):,1],truth_df.iloc[-3*len(prediction_df):,0],'-', label='Truth')\n",
    "        plt.plot_date(prediction_df.iloc[:,1],prediction_df.iloc[:,0],'-',label ='Prediction')\n",
    "        plt.legend()\n",
    "        plt.show();\n",
    "\n",
    "        print('mean absolute scaled error: ')\n",
    "        print(mean_absolute_scaled_error(predictions_df['store_truth'].iloc[-(len(prediction_df)+1):],\n",
    "                                         predictions_df[f'store_pred_{N_HIDDEN}'],\n",
    "                                         truth_df.iloc[:-len(prediction_df),0]))\n",
    "        print('\\n','mean squared error: ')\n",
    "        print(mean_squared_error(predictions_df['store_truth'].iloc[-(len(prediction_df)+1):],\n",
    "                                         predictions_df[f'store_pred_{N_HIDDEN}']))\n",
    "        print('\\n','root mean squared error: ')\n",
    "        print((mean_squared_error(predictions_df['store_truth'].iloc[-(len(prediction_df)+1):],\n",
    "                                         predictions_df[f'store_pred_{N_HIDDEN}']))**(1/2)) \n",
    "\n",
    "        iteration_end = time.monotonic()\n",
    "        print('\\n',\"Iteration time: \", iteration_end - iteration_start)\n",
    "\n",
    "        mean_abs_allf.append(mean_absolute_scaled_error(predictions_df['store_truth'].iloc[-(len(prediction_df)+1):],\n",
    "                                         predictions_df[f'store_pred_{N_HIDDEN}'],\n",
    "                                         truth_df.iloc[:-len(prediction_df),0]))\n",
    "\n",
    "        mean_sqr_allf.append(mean_squared_error(predictions_df['store_truth'].iloc[-(len(prediction_df)+1):],\n",
    "                                         predictions_df[f'store_pred_{N_HIDDEN}']))\n",
    "\n",
    "        time_allf.append(iteration_end - iteration_start)\n",
    "\n",
    "    predictions_df.to_csv(f'{folder_path}/Rossmann_LSTM_hidden{N_HIDDEN}.csv')\n",
    "\n",
    "    %store mean_abs_allf\n",
    "    %store mean_sqr_allf\n",
    "    %store time_allf\n",
    "    \n",
    "    print(mean_abs_allf)\n",
    "    print(mean_sqr_allf)\n",
    "    print(time_allf)\n",
    "    \n",
    "else:\n",
    "    %store -r mean_abs_allf\n",
    "    %store -r mean_sqr_allf\n",
    "    %store -r time_allf\n",
    "    \n",
    "    print(mean_abs_allf)\n",
    "    print(mean_sqr_allf)\n",
    "    print(time_allf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f5448a",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = 'Predictions/grid_search_corr'\n",
    "\n",
    "if corr_train == True:\n",
    "    corr_feat = pd.read_csv('Predictions/Single_Run/correlation_df.csv')\n",
    "    corr_feat.drop(columns = 'all_features', inplace = True)\n",
    "    corr_dic = {}\n",
    "\n",
    "    try:\n",
    "        os.mkdir(f'{folder_path}')\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    for corr_col in tqdm(corr_feat.columns):\n",
    "        \n",
    "        mean_abs_corrf = []\n",
    "        mean_sqr_corrf = []\n",
    "        time_corrf = []\n",
    "        \n",
    "        for N_HIDDEN in hidden_values:\n",
    "            torch.manual_seed(8)\n",
    "            np.random.seed(8)\n",
    "            pl.seed_everything(8);\n",
    "        \n",
    "            iteration_start = time.monotonic()\n",
    "            \n",
    "            hidden_dic = {}\n",
    "\n",
    "            class SalesPredictionModel(nn.Module):\n",
    "                def __init__(self, n_features, n_hidden = N_HIDDEN, n_layers = N_LAYERS):\n",
    "                    super().__init__()\n",
    "                    self.n_hidden = n_hidden\n",
    "\n",
    "                    self.lstm = nn.LSTM(\n",
    "                        input_size = n_features,\n",
    "                        hidden_size = n_hidden,\n",
    "                        batch_first = True,\n",
    "                        num_layers = n_layers,\n",
    "                        dropout = 0.2\n",
    "                    )\n",
    "                    self.regressor = nn.Linear(n_hidden,1)\n",
    "\n",
    "                def forward(self,x):\n",
    "                    self.lstm.flatten_parameters()\n",
    "\n",
    "                    _, (hidden, _) = self.lstm(x)\n",
    "                    out = hidden[-1]\n",
    "\n",
    "                    return self.regressor(out)\n",
    "\n",
    "\n",
    "            class SalesPredictor(pl.LightningModule):\n",
    "\n",
    "                def __init__(self, n_features: int):\n",
    "                    super().__init__()\n",
    "                    self.model=SalesPredictionModel(n_features)\n",
    "                    self.criterion = nn.MSELoss()\n",
    "\n",
    "                def forward(self, x, labels= None):\n",
    "                    output = self.model(x)\n",
    "                    loss = 0\n",
    "                    if labels is not None:\n",
    "                        loss = self.criterion(output, labels.unsqueeze(dim=1))\n",
    "                    return loss, output\n",
    "\n",
    "                def training_step(self, batch, batch_index):\n",
    "                    sequences = batch['sequence']\n",
    "                    labels = batch['label']\n",
    "\n",
    "                    loss, outputs = self(sequences, labels)\n",
    "                    self.log('train_loss', loss, prog_bar = True, logger=False)\n",
    "                    return loss\n",
    "\n",
    "                def validation_step(self, batch, batch_index):\n",
    "                    sequences = batch['sequence']\n",
    "                    labels = batch['label']\n",
    "\n",
    "                    loss, outputs = self(sequences, labels)\n",
    "                    self.log('val_loss', loss, prog_bar = True, logger=False)\n",
    "                    return loss\n",
    "\n",
    "                def test_step(self, batch, batch_index):\n",
    "                    sequences = batch['sequence']\n",
    "                    labels = batch['label']\n",
    "\n",
    "                    loss, outputs = self(sequences, labels)\n",
    "                    self.log('test_loss', loss, prog_bar = True, logger=False)\n",
    "                    return loss\n",
    "\n",
    "                def configure_optimizers(self):\n",
    "                    return optim.AdamW(self.parameters(), lr = LEARNING)\n",
    "\n",
    "\n",
    "            #makes SHAP calculations for all stores inside the rossmann_treated dataset if removed the [:1]\n",
    "\n",
    "            #to omit outputs\n",
    "            #with io.capture_output() as captured:\n",
    "            df = Rossmann_df.drop(columns  = 'Date')\n",
    "    \n",
    "            features = list(corr_feat[corr_col].fillna(0))\n",
    "\n",
    "            features = [x for x in features if x != 0]\n",
    "\n",
    "            #return all columns names ('features') except for customers, since it's not an available \n",
    "            #information for future points\n",
    "            features_df = features_dataframe(df,features) \n",
    "            #returns dataframe with the features to be analised\n",
    "\n",
    "            #split into test and train and minmaxscaler\n",
    "            train_df, test_df, train_size =  train_test_spliter(105,features_df)\n",
    "            train_df, test_df, scaler = data_scaler(train_df,test_df)\n",
    "            #make sequences with the data\n",
    "            train_sequences = create_sequences(train_df,TGT,SEQUENCE_LENGTH)\n",
    "            test_sequences = create_sequences (test_df,TGT,SEQUENCE_LENGTH)\n",
    "\n",
    "            #trains the model and store the most recent checkpoints removing previous ones if existing\n",
    "            data_module = SalesDataModule(train_sequences, test_sequences, batch_size = BATCH_SIZE)\n",
    "            data_module.setup()\n",
    "            train_dataset = Dataset(train_sequences)\n",
    "            test_dataset = Dataset(test_sequences)\n",
    "            model = SalesPredictor(n_features = train_df.shape[1])\n",
    "\n",
    "\n",
    "\n",
    "            try:\n",
    "                os.remove(f\"{folder_path}/Checkpoints/Rossmann_LSTM_hidden{N_HIDDEN}_corr{corr_col}.ckpt\")\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            checkpoint_callback = ModelCheckpoint(\n",
    "                dirpath = f'{folder_path}/Checkpoints',\n",
    "                filename = f'Rossmann_LSTM_hidden{N_HIDDEN}_corr{corr_col}',\n",
    "                save_top_k = 1,\n",
    "                verbose = False ,\n",
    "                monitor = 'val_loss',\n",
    "                mode = 'min'\n",
    "            )\n",
    "            logger = TensorBoardLogger('lightning_logs', name = 'btc-price')\n",
    "            early_stopping_callback = EarlyStopping(monitor= 'val_loss', patience = PATIENCE)\n",
    "            trainer = pl.Trainer(\n",
    "                logger = logger,\n",
    "                callbacks=[early_stopping_callback, checkpoint_callback],\n",
    "                max_epochs = N_EPOCHS,\n",
    "                gpus = 0,\n",
    "            )\n",
    "            trainer.fit(model, data_module)\n",
    "\n",
    "            #load the best model from checkpoint\n",
    "            trained_model = SalesPredictor.load_from_checkpoint(\n",
    "            f'{folder_path}/Checkpoints/Rossmann_LSTM_hidden{N_HIDDEN}_corr{corr_col}.ckpt',\n",
    "            n_features = train_df.shape[1]\n",
    "            )\n",
    "\n",
    "            predictions = []\n",
    "            labels = []\n",
    "\n",
    "            for item in test_dataset:\n",
    "                sequence = item['sequence']\n",
    "                label = item['label']\n",
    "\n",
    "                if len(predictions) > SEQUENCE_LENGTH:\n",
    "                    for j in range(SEQUENCE_LENGTH):\n",
    "                        sequence[-SEQUENCE_LENGTH+j,0] = float(predictions[-SEQUENCE_LENGTH+j])\n",
    "                else: \n",
    "                    for j in range(len(predictions)):\n",
    "                        sequence[-len(predictions)+j,0] = float(predictions[-len(predictions)+j])\n",
    "\n",
    "                _,output = trained_model(sequence.unsqueeze(dim=0))\n",
    "                predictions.append(output.item())\n",
    "                labels.append(label.item())\n",
    "\n",
    "\n",
    "\n",
    "            descaler = MinMaxScaler()\n",
    "            descaler.min_, descaler.scale_ = scaler.min_[0], scaler.scale_[0]\n",
    "\n",
    "            predictions_descaled = descale(descaler,predictions)\n",
    "            labels_descaled = descale(descaler,labels)\n",
    "\n",
    "            test_data = df[train_size+1:]\n",
    "            test_sequences_data = test_data.iloc[SEQUENCE_LENGTH:]\n",
    "\n",
    "            dates = matplotlib.dates.date2num(Rossmann_df.iloc[-len(predictions_descaled):].Date)\n",
    "            full_dates = matplotlib.dates.date2num(Rossmann_df.Date.tolist())\n",
    "            \n",
    "            dic= {}\n",
    "            dic[f'store_pred_{N_HIDDEN}'] = predictions_descaled\n",
    "            pred_df = pd.DataFrame.from_dict(dic)\n",
    "            pred_df = pred_df.shift(-1)\n",
    "\n",
    "\n",
    "            dic = {}\n",
    "            dic[f'store_pred_dates'] = dates\n",
    "            dic[f'store_truth'] = Rossmann_df[TGT].iloc[-len(pred_df):]\n",
    "            truth_df = pd.DataFrame.from_dict(dic)\n",
    "            \n",
    "            if N_HIDDEN != hidden_values[0]:\n",
    "                predictions_df = predictions_df.join(pred_df, how = 'left')\n",
    "            else:\n",
    "                truth_df.reset_index(inplace = True)\n",
    "                truth_df.drop('index', axis=1)\n",
    "                predictions_df = truth_df\n",
    "                predictions_df = predictions_df.join(pred_df, how = 'left')\n",
    "                predictions_df = predictions_df.iloc[:-1]\n",
    "\n",
    "            display(predictions_df)\n",
    "            \n",
    "            dic = {}\n",
    "            dic[f'store_truth'] = Rossmann_df[TGT]\n",
    "            dic[f'store_truth_dates'] = full_dates\n",
    "            truth_df = pd.DataFrame.from_dict(dic)\n",
    "            \n",
    "            dic= {}\n",
    "            dic[f'store_pred'] = predictions_descaled\n",
    "            dic[f'store_pred_dates'] = dates\n",
    "            prediction_df = pd.DataFrame.from_dict(dic)\n",
    "            prediction_df['store_pred'] =prediction_df['store_pred'].shift(-1)\n",
    "            \n",
    "            plt.figure(figsize=(21, 7))\n",
    "            plt.plot_date(truth_df.iloc[-3*len(prediction_df):,1],truth_df.iloc[-3*len(prediction_df):,0],'-', label='Truth')\n",
    "            plt.plot_date(prediction_df.iloc[:,1],prediction_df.iloc[:,0],'-',label ='Prediction')\n",
    "            plt.legend()\n",
    "            plt.show();\n",
    "            \n",
    "            iteration_end = time.monotonic()\n",
    "            \n",
    "            predictions_descaled = np.where(predictions_descaled<0, 0, predictions_descaled)\n",
    "\n",
    "            mean_abs_corrf.append(mean_absolute_scaled_error(predictions_df['store_truth'].iloc[-(len(prediction_df)+1):],\n",
    "                                             predictions_df[f'store_pred_{N_HIDDEN}'],\n",
    "                                             truth_df.iloc[:-len(prediction_df),0]))\n",
    "\n",
    "            mean_sqr_corrf.append(mean_squared_error(predictions_df['store_truth'].iloc[-(len(prediction_df)+1):],\n",
    "                                             predictions_df[f'store_pred_{N_HIDDEN}'])**(1/2))\n",
    "\n",
    "            time_corrf.append(iteration_end - iteration_start)\n",
    "            \n",
    "            hidden_dic['mase'] = mean_abs_corrf\n",
    "            hidden_dic['mse']  = mean_sqr_corrf\n",
    "            hidden_dic['time'] = time_corrf\n",
    "            \n",
    "            print(corr_col)\n",
    "            print(N_HIDDEN)\n",
    "            print(hidden_dic)\n",
    "            \n",
    "        predictions_df.to_csv(f'{folder_path}/Rossmann_LSTM_correlation.csv')\n",
    "        corr_dic[corr_col] = hidden_dic\n",
    "    %store corr_dic\n",
    "else:\n",
    "    %store -r corr_dic\n",
    "    corr_feat = pd.read_csv('Predictions/Single_Run/correlation_df.csv')\n",
    "\n",
    "    for i in corr_feat.columns[1:]:\n",
    "        plt.figure(figsize=(21, 7))\n",
    "        predictions_corr = pd.read_csv(f'{folder_path}/Rossmann_LSTM_{i}.csv')\n",
    "        plt.plot_date(predictions_corr['store_pred_dates'],\n",
    "                          predictions_corr['store_truth'],'--', label='Truth')\n",
    "        for N in hidden_values[:3]:\n",
    "            #display(predictions_corr)\n",
    "\n",
    "            plt.plot_date(predictions_corr['store_pred_dates'],\n",
    "                      predictions_corr[f'store_pred_{N}'],'-', label=f'{i},_Hidden_size_=_{N}')\n",
    "            \n",
    "            mase = mean_absolute_scaled_error(predictions_corr['store_pred_dates'],\n",
    "                                                    predictions_corr[f'store_pred_{N}'],\n",
    "                                                     Rossmann_df[TGT].iloc[:-len(predictions_corr)])\n",
    "\n",
    "            mse = (mean_squared_error(predictions_corr['store_pred_dates'],\n",
    "                                            predictions_corr[f'store_pred_{N}']))\n",
    "            print(f'{i},_Hidden_size_=_{N} mase: ', mase, ' rmse: ', (mse)**(1/2))\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        \n",
    "        plt.figure(figsize=(21, 7))\n",
    "        plt.plot_date(predictions_corr['store_pred_dates'],\n",
    "                      predictions_corr['store_truth'],'--', label='Truth')\n",
    "        for N in hidden_values[3:]:\n",
    "            #display(predictions_corr)\n",
    "\n",
    "            plt.plot_date(predictions_corr['store_pred_dates'],\n",
    "                      predictions_corr[f'store_pred_{N}'],'-', label=f'{i},_Hidden_size_=_{N}')\n",
    "            \n",
    "            mase = mean_absolute_scaled_error(predictions_corr['store_pred_dates'],\n",
    "                                                    predictions_corr[f'store_pred_{N}'],\n",
    "                                                     Rossmann_df[TGT].iloc[:-len(predictions_corr)])\n",
    "\n",
    "            mse = (mean_squared_error(predictions_corr['store_pred_dates'],\n",
    "                                            predictions_corr[f'store_pred_{N}']))\n",
    "            print(f'{i},_Hidden_size_=_{N} mase: ', mase, ' rmse: ', (mse)**(1/2))\n",
    "        plt.legend()  \n",
    "        plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf8c67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Boruta_GB == True:\n",
    "    folder_path = 'Predictions/grid_search_BoGB'\n",
    "    BoGB_feat = pd.read_csv('Predictions/Single_Run/borutaGB_df.csv')\n",
    "    \n",
    "    try:\n",
    "        os.mkdir(f'{folder_path}')\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    mean_abs_BoGB = []\n",
    "    mean_sqr_BoGB = []\n",
    "    time_BoGB = []\n",
    "\n",
    "    for N_HIDDEN in hidden_values:\n",
    "        torch.manual_seed(8)\n",
    "        np.random.seed(8)\n",
    "        pl.seed_everything(8);\n",
    "        \n",
    "        iteration_start = time.monotonic()\n",
    "\n",
    "        class SalesPredictionModel(nn.Module):\n",
    "            def __init__(self, n_features, n_hidden = N_HIDDEN, n_layers = N_LAYERS):\n",
    "                super().__init__()\n",
    "                self.n_hidden = n_hidden\n",
    "\n",
    "                self.lstm = nn.LSTM(\n",
    "                    input_size = n_features,\n",
    "                    hidden_size = n_hidden,\n",
    "                    batch_first = True,\n",
    "                    num_layers = n_layers,\n",
    "                    dropout = 0.2\n",
    "                )\n",
    "                self.regressor = nn.Linear(n_hidden,1)\n",
    "\n",
    "            def forward(self,x):\n",
    "                self.lstm.flatten_parameters()\n",
    "\n",
    "                _, (hidden, _) = self.lstm(x)\n",
    "                out = hidden[-1]\n",
    "\n",
    "                return self.regressor(out)\n",
    "\n",
    "\n",
    "        class SalesPredictor(pl.LightningModule):\n",
    "\n",
    "            def __init__(self, n_features: int):\n",
    "                super().__init__()\n",
    "                self.model=SalesPredictionModel(n_features)\n",
    "                self.criterion = nn.MSELoss()\n",
    "\n",
    "            def forward(self, x, labels= None):\n",
    "                output = self.model(x)\n",
    "                loss = 0\n",
    "                if labels is not None:\n",
    "                    loss = self.criterion(output, labels.unsqueeze(dim=1))\n",
    "                return loss, output\n",
    "\n",
    "            def training_step(self, batch, batch_index):\n",
    "                sequences = batch['sequence']\n",
    "                labels = batch['label']\n",
    "\n",
    "                loss, outputs = self(sequences, labels)\n",
    "                self.log('train_loss', loss, prog_bar = True, logger=False)\n",
    "                return loss\n",
    "\n",
    "            def validation_step(self, batch, batch_index):\n",
    "                sequences = batch['sequence']\n",
    "                labels = batch['label']\n",
    "\n",
    "                loss, outputs = self(sequences, labels)\n",
    "                self.log('val_loss', loss, prog_bar = True, logger=False)\n",
    "                return loss\n",
    "\n",
    "            def test_step(self, batch, batch_index):\n",
    "                sequences = batch['sequence']\n",
    "                labels = batch['label']\n",
    "\n",
    "                loss, outputs = self(sequences, labels)\n",
    "                self.log('test_loss', loss, prog_bar = True, logger=False)\n",
    "                return loss\n",
    "\n",
    "            def configure_optimizers(self):\n",
    "                return optim.AdamW(self.parameters(), lr = LEARNING)\n",
    "\n",
    "\n",
    "        #makes SHAP calculations for all stores inside the rossmann_treated dataset if removed the [:1]\n",
    "\n",
    "        #to omit outputs\n",
    "        #with io.capture_output() as captured:\n",
    "        df = Rossmann_df.drop(columns  = 'Date')\n",
    "\n",
    "        features = list(BoGB_feat['important'].fillna(0))\n",
    "\n",
    "        features = [x for x in features if x != 0]\n",
    "        \n",
    "        #return all columns names ('features') except for customers, since it's not an available \n",
    "        #information for future points\n",
    "        features_df = features_dataframe(df,features) \n",
    "        #returns dataframe with the features to be analised\n",
    "\n",
    "        #split into test and train and minmaxscaler\n",
    "        train_df, test_df, train_size =  train_test_spliter(105,features_df)\n",
    "        train_df, test_df, scaler = data_scaler(train_df,test_df)\n",
    "        #make sequences with the data\n",
    "        train_sequences = create_sequences(train_df,TGT,SEQUENCE_LENGTH)\n",
    "        test_sequences = create_sequences (test_df,TGT,SEQUENCE_LENGTH)\n",
    "\n",
    "        #trains the model and store the most recent checkpoints removing previous ones if existing\n",
    "        data_module = SalesDataModule(train_sequences, test_sequences, batch_size = BATCH_SIZE)\n",
    "        data_module.setup()\n",
    "        train_dataset = Dataset(train_sequences)\n",
    "        test_dataset = Dataset(test_sequences)\n",
    "        model = SalesPredictor(n_features = train_df.shape[1])\n",
    "\n",
    "\n",
    "\n",
    "        try:\n",
    "            os.remove(f\"{folder_path}/Checkpoints/Rossmann_LSTM_hidden{N_HIDDEN}_Boruta_GB.ckpt\")\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        checkpoint_callback = ModelCheckpoint(\n",
    "            dirpath = f'{folder_path}/Checkpoints',\n",
    "            filename = f'Rossmann_LSTM_hidden{N_HIDDEN}_Boruta_GB',\n",
    "            save_top_k = 1,\n",
    "            verbose = False ,\n",
    "            monitor = 'val_loss',\n",
    "            mode = 'min'\n",
    "        )\n",
    "        logger = TensorBoardLogger('lightning_logs', name = 'btc-price')\n",
    "        early_stopping_callback = EarlyStopping(monitor= 'val_loss', patience = PATIENCE)\n",
    "        trainer = pl.Trainer(\n",
    "            logger = logger,\n",
    "            callbacks=[early_stopping_callback, checkpoint_callback],\n",
    "            max_epochs = N_EPOCHS,\n",
    "            gpus = 0,\n",
    "        )\n",
    "        trainer.fit(model, data_module)\n",
    "\n",
    "        #load the best model from checkpoint\n",
    "        trained_model = SalesPredictor.load_from_checkpoint(\n",
    "        f'{folder_path}/Checkpoints/Rossmann_LSTM_hidden{N_HIDDEN}_Boruta_GB.ckpt',\n",
    "        n_features = train_df.shape[1]\n",
    "        )\n",
    "\n",
    "        predictions = []\n",
    "        labels = []\n",
    "\n",
    "        for item in test_dataset:\n",
    "            sequence = item['sequence']\n",
    "            label = item['label']\n",
    "\n",
    "            if len(predictions) > SEQUENCE_LENGTH:\n",
    "                for j in range(SEQUENCE_LENGTH):\n",
    "                    sequence[-SEQUENCE_LENGTH+j,0] = float(predictions[-SEQUENCE_LENGTH+j])\n",
    "            else: \n",
    "                for j in range(len(predictions)):\n",
    "                    sequence[-len(predictions)+j,0] = float(predictions[-len(predictions)+j])\n",
    "\n",
    "            _,output = trained_model(sequence.unsqueeze(dim=0))\n",
    "            predictions.append(output.item())\n",
    "            labels.append(label.item())\n",
    "\n",
    "\n",
    "\n",
    "        descaler = MinMaxScaler()\n",
    "        descaler.min_, descaler.scale_ = scaler.min_[0], scaler.scale_[0]\n",
    "\n",
    "        predictions_descaled = descale(descaler,predictions)\n",
    "        labels_descaled = descale(descaler,labels)\n",
    "\n",
    "        test_data = df[train_size+1:]\n",
    "        test_sequences_data = test_data.iloc[SEQUENCE_LENGTH:]\n",
    "\n",
    "        dates = matplotlib.dates.date2num(Rossmann_df.iloc[-len(predictions_descaled):].datetime.tolist())\n",
    "        full_dates = matplotlib.dates.date2num(Rossmann_df.datetime.tolist())\n",
    "\n",
    "        predictions_descaled = np.where(predictions_descaled<0, 0, predictions_descaled)\n",
    "\n",
    "\n",
    "        dic= {}\n",
    "        dic[f'store_pred_{N_HIDDEN}'] = predictions_descaled\n",
    "        pred_df = pd.DataFrame.from_dict(dic)\n",
    "        pred_df = pred_df.shift(-1)\n",
    "\n",
    "\n",
    "        dic = {}\n",
    "        dic[f'store_pred_dates'] = dates\n",
    "        dic[f'store_truth'] = Rossmann_df[TGT].iloc[-len(pred_df):]\n",
    "        truth_df = pd.DataFrame.from_dict(dic)\n",
    "\n",
    "\n",
    "        if N_HIDDEN != hidden_values[0]:\n",
    "            predictions_df = predictions_df.join(pred_df, how = 'left')\n",
    "        else:\n",
    "            truth_df.reset_index(inplace = True)\n",
    "            truth_df.drop('index', axis=1)\n",
    "            predictions_df = truth_df\n",
    "            predictions_df = predictions_df.join(pred_df, how = 'left')\n",
    "            predictions_df = predictions_df.iloc[:-1]\n",
    "\n",
    "        #display(predictions_df)\n",
    "        \n",
    "        dic = {}\n",
    "        dic[f'store_truth'] = Rossmann_df[TGT]\n",
    "        dic[f'store_truth_dates'] = full_dates\n",
    "        truth_df = pd.DataFrame.from_dict(dic)\n",
    "\n",
    "        dic= {}\n",
    "        dic[f'store_pred'] = predictions_descaled\n",
    "        dic[f'store_pred_dates'] = dates\n",
    "        prediction_df = pd.DataFrame.from_dict(dic)\n",
    "        prediction_df['store_pred'] =prediction_df['store_pred'].shift(-1)\n",
    "        \n",
    "        plt.figure(figsize=(21, 7))\n",
    "        plt.plot_date(truth_df.iloc[-3*len(prediction_df):,1],truth_df.iloc[-3*len(prediction_df):,0],'-', label='Truth')\n",
    "        plt.plot_date(prediction_df.iloc[:,1],prediction_df.iloc[:,0],'-',label ='Prediction')\n",
    "        plt.legend()\n",
    "        plt.show();\n",
    "\n",
    "        print('mean absolute scaled error: ')\n",
    "        print(mean_absolute_scaled_error(predictions_df['store_truth'].iloc[-(len(prediction_df)+1):],\n",
    "                                         predictions_df[f'store_pred_{N_HIDDEN}'],\n",
    "                                         truth_df.iloc[:-len(prediction_df),0]))\n",
    "        print('\\n','mean squared error: ')\n",
    "        print(mean_squared_error(predictions_df['store_truth'].iloc[-(len(prediction_df)+1):],\n",
    "                                         predictions_df[f'store_pred_{N_HIDDEN}']))\n",
    "        print('\\n','root mean squared error: ')\n",
    "        print((mean_squared_error(predictions_df['store_truth'].iloc[-(len(prediction_df)+1):],\n",
    "                                         predictions_df[f'store_pred_{N_HIDDEN}']))**(1/2)) \n",
    "\n",
    "        iteration_end = time.monotonic()\n",
    "        print('\\n',\"Iteration time: \", iteration_end - iteration_start)\n",
    "\n",
    "        mean_abs_BoGB.append(mean_absolute_scaled_error(predictions_df['store_truth'].iloc[-(len(prediction_df)+1):],\n",
    "                                         predictions_df[f'store_pred_{N_HIDDEN}'],\n",
    "                                         truth_df.iloc[:-len(prediction_df),0]))\n",
    "\n",
    "        mean_sqr_BoGB.append(mean_squared_error(predictions_df['store_truth'].iloc[-(len(prediction_df)+1):],\n",
    "                                         predictions_df[f'store_pred_{N_HIDDEN}'])**(1/2))\n",
    "\n",
    "        time_BoGB.append(iteration_end - iteration_start)\n",
    "\n",
    "    predictions_df.to_csv(f'{folder_path}/Rossmann_LSTM_hidden_BoGB.csv')\n",
    "\n",
    "    %store mean_abs_BoGB\n",
    "    %store mean_sqr_BoGB\n",
    "    %store time_BoGB\n",
    " \n",
    "else:\n",
    "    %store -r mean_abs_BoGB\n",
    "    %store -r mean_sqr_BoGB\n",
    "    %store -r time_BoGB\n",
    "    \n",
    "    print(mean_abs_BoGB)\n",
    "    print(mean_sqr_BoGB)\n",
    "    print(time_BoGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765e43fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Boruta_RF == True:\n",
    "    folder_path = 'Predictions/grid_search_BoRF'\n",
    "    BoRF_feat = pd.read_csv('Predictions/Single_Run/borutaRF_df.csv')\n",
    "    \n",
    "    try:\n",
    "        os.mkdir(f'{folder_path}')\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    mean_abs_BoRF = []\n",
    "    mean_sqr_BoRF = []\n",
    "    time_BoRF = []\n",
    "\n",
    "    for N_HIDDEN in hidden_values:\n",
    "        torch.manual_seed(8)\n",
    "        np.random.seed(8)\n",
    "        pl.seed_everything(8);\n",
    "        iteration_start = time.monotonic()\n",
    "        \n",
    "        class SalesPredictionModel(nn.Module):\n",
    "            def __init__(self, n_features, n_hidden = N_HIDDEN, n_layers = N_LAYERS):\n",
    "                super().__init__()\n",
    "                self.n_hidden = n_hidden\n",
    "\n",
    "                self.lstm = nn.LSTM(\n",
    "                    input_size = n_features,\n",
    "                    hidden_size = n_hidden,\n",
    "                    batch_first = True,\n",
    "                    num_layers = n_layers,\n",
    "                    dropout = 0.2\n",
    "                )\n",
    "                self.regressor = nn.Linear(n_hidden,1)\n",
    "\n",
    "            def forward(self,x):\n",
    "                self.lstm.flatten_parameters()\n",
    "\n",
    "                _, (hidden, _) = self.lstm(x)\n",
    "                out = hidden[-1]\n",
    "\n",
    "                return self.regressor(out)\n",
    "\n",
    "\n",
    "        class SalesPredictor(pl.LightningModule):\n",
    "\n",
    "            def __init__(self, n_features: int):\n",
    "                super().__init__()\n",
    "                self.model=SalesPredictionModel(n_features)\n",
    "                self.criterion = nn.MSELoss()\n",
    "\n",
    "            def forward(self, x, labels= None):\n",
    "                output = self.model(x)\n",
    "                loss = 0\n",
    "                if labels is not None:\n",
    "                    loss = self.criterion(output, labels.unsqueeze(dim=1))\n",
    "                return loss, output\n",
    "\n",
    "            def training_step(self, batch, batch_index):\n",
    "                sequences = batch['sequence']\n",
    "                labels = batch['label']\n",
    "\n",
    "                loss, outputs = self(sequences, labels)\n",
    "                self.log('train_loss', loss, prog_bar = True, logger=False)\n",
    "                return loss\n",
    "\n",
    "            def validation_step(self, batch, batch_index):\n",
    "                sequences = batch['sequence']\n",
    "                labels = batch['label']\n",
    "\n",
    "                loss, outputs = self(sequences, labels)\n",
    "                self.log('val_loss', loss, prog_bar = True, logger=False)\n",
    "                return loss\n",
    "\n",
    "            def test_step(self, batch, batch_index):\n",
    "                sequences = batch['sequence']\n",
    "                labels = batch['label']\n",
    "\n",
    "                loss, outputs = self(sequences, labels)\n",
    "                self.log('test_loss', loss, prog_bar = True, logger=False)\n",
    "                return loss\n",
    "\n",
    "            def configure_optimizers(self):\n",
    "                return optim.AdamW(self.parameters(), lr = LEARNING)\n",
    "\n",
    "\n",
    "        #makes SHAP calculations for all stores inside the rossmann_treated dataset if removed the [:1]\n",
    "\n",
    "        #to omit outputs\n",
    "        #with io.capture_output() as captured:\n",
    "        df = Rossmann_df.drop(columns  = 'Date')\n",
    "\n",
    "        features = list(BoRF_feat['important'].fillna(0))\n",
    "\n",
    "        features = [x for x in features if x != 0]\n",
    "\n",
    "        #return all columns names ('features') except for customers, since it's not an available \n",
    "        #information for future points\n",
    "        features_df = features_dataframe(df,features) \n",
    "        #returns dataframe with the features to be analised\n",
    "\n",
    "        #split into test and train and minmaxscaler\n",
    "        train_df, test_df, train_size =  train_test_spliter(105,features_df)\n",
    "        train_df, test_df, scaler = data_scaler(train_df,test_df)\n",
    "        #make sequences with the data\n",
    "        train_sequences = create_sequences(train_df,TGT,SEQUENCE_LENGTH)\n",
    "        test_sequences = create_sequences (test_df,TGT,SEQUENCE_LENGTH)\n",
    "\n",
    "        #trains the model and store the most recent checkpoints removing previous ones if existing\n",
    "        data_module = SalesDataModule(train_sequences, test_sequences, batch_size = BATCH_SIZE)\n",
    "        data_module.setup()\n",
    "        train_dataset = Dataset(train_sequences)\n",
    "        test_dataset = Dataset(test_sequences)\n",
    "        model = SalesPredictor(n_features = train_df.shape[1])\n",
    "\n",
    "\n",
    "\n",
    "        try:\n",
    "            os.remove(f\"{folder_path}/Checkpoints/Rossmann_LSTM_hidden{N_HIDDEN}_Boruta_RF.ckpt\")\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        checkpoint_callback = ModelCheckpoint(\n",
    "            dirpath = f'{folder_path}/Checkpoints',\n",
    "            filename = f'Rossmann_LSTM_hidden{N_HIDDEN}_Boruta_RF',\n",
    "            save_top_k = 1,\n",
    "            verbose = False ,\n",
    "            monitor = 'val_loss',\n",
    "            mode = 'min'\n",
    "        )\n",
    "        logger = TensorBoardLogger('lightning_logs', name = 'btc-price')\n",
    "        early_stopping_callback = EarlyStopping(monitor= 'val_loss', patience = PATIENCE)\n",
    "        trainer = pl.Trainer(\n",
    "            logger = logger,\n",
    "            callbacks=[early_stopping_callback, checkpoint_callback],\n",
    "            max_epochs = N_EPOCHS,\n",
    "            gpus = 0,\n",
    "        )\n",
    "        trainer.fit(model, data_module)\n",
    "\n",
    "        #load the best model from checkpoint\n",
    "        trained_model = SalesPredictor.load_from_checkpoint(\n",
    "        f'{folder_path}/Checkpoints/Rossmann_LSTM_hidden{N_HIDDEN}_Boruta_RF.ckpt',\n",
    "        n_features = train_df.shape[1]\n",
    "        )\n",
    "\n",
    "        predictions = []\n",
    "        labels = []\n",
    "\n",
    "        for item in test_dataset:\n",
    "            sequence = item['sequence']\n",
    "            label = item['label']\n",
    "\n",
    "            if len(predictions) > SEQUENCE_LENGTH:\n",
    "                for j in range(SEQUENCE_LENGTH):\n",
    "                    sequence[-SEQUENCE_LENGTH+j,0] = float(predictions[-SEQUENCE_LENGTH+j])\n",
    "            else: \n",
    "                for j in range(len(predictions)):\n",
    "                    sequence[-len(predictions)+j,0] = float(predictions[-len(predictions)+j])\n",
    "\n",
    "            _,output = trained_model(sequence.unsqueeze(dim=0))\n",
    "            predictions.append(output.item())\n",
    "            labels.append(label.item())\n",
    "\n",
    "\n",
    "\n",
    "        descaler = MinMaxScaler()\n",
    "        descaler.min_, descaler.scale_ = scaler.min_[0], scaler.scale_[0]\n",
    "\n",
    "        predictions_descaled = descale(descaler,predictions)\n",
    "        labels_descaled = descale(descaler,labels)\n",
    "\n",
    "        test_data = df[train_size+1:]\n",
    "        test_sequences_data = test_data.iloc[SEQUENCE_LENGTH:]\n",
    "\n",
    "        dates = matplotlib.dates.date2num(Rossmann_df.iloc[-len(predictions_descaled):].Date.tolist())\n",
    "        full_dates = matplotlib.dates.date2num(Rossmann_df.Date.tolist())\n",
    "\n",
    "        predictions_descaled = np.where(predictions_descaled<0, 0, predictions_descaled)\n",
    "\n",
    "\n",
    "        dic= {}\n",
    "        dic[f'store_pred_{N_HIDDEN}'] = predictions_descaled\n",
    "        pred_df = pd.DataFrame.from_dict(dic)\n",
    "        pred_df = pred_df.shift(-1)\n",
    "\n",
    "\n",
    "        dic = {}\n",
    "        dic[f'store_pred_dates'] = dates\n",
    "        dic[f'store_truth'] = Rossmann_df[TGT].iloc[-len(pred_df):]\n",
    "        truth_df = pd.DataFrame.from_dict(dic)\n",
    "\n",
    "\n",
    "        if N_HIDDEN != hidden_values[0]:\n",
    "            predictions_df = predictions_df.join(pred_df, how = 'left')\n",
    "        else:\n",
    "            truth_df.reset_index(inplace = True)\n",
    "            truth_df.drop('index', axis=1)\n",
    "            predictions_df = truth_df\n",
    "            predictions_df = predictions_df.join(pred_df, how = 'left')\n",
    "            predictions_df = predictions_df.iloc[:-1]\n",
    "\n",
    "        #display(predictions_df)\n",
    "        \n",
    "        dic = {}\n",
    "        dic[f'store_truth'] = Rossmann_df[TGT]\n",
    "        dic[f'store_truth_dates'] = full_dates\n",
    "        truth_df = pd.DataFrame.from_dict(dic)\n",
    "\n",
    "        dic= {}\n",
    "        dic[f'store_pred'] = predictions_descaled\n",
    "        dic[f'store_pred_dates'] = dates\n",
    "        prediction_df = pd.DataFrame.from_dict(dic)\n",
    "        prediction_df['store_pred'] =prediction_df['store_pred'].shift(-1)\n",
    "        \n",
    "        plt.figure(figsize=(21, 7))\n",
    "        plt.plot_date(truth_df.iloc[-3*len(prediction_df):,1],truth_df.iloc[-3*len(prediction_df):,0],'-', label='Truth')\n",
    "        plt.plot_date(prediction_df.iloc[:,1],prediction_df.iloc[:,0],'-',label ='Prediction')\n",
    "        plt.legend()\n",
    "        plt.show();\n",
    "\n",
    "        print('mean absolute scaled error: ')\n",
    "        print(mean_absolute_scaled_error(predictions_df['store_truth'].iloc[-(len(prediction_df)+1):],\n",
    "                                         predictions_df[f'store_pred_{N_HIDDEN}'],\n",
    "                                         truth_df.iloc[:-len(prediction_df),0]))\n",
    "        print('\\n','mean squared error: ')\n",
    "        print(mean_squared_error(predictions_df['store_truth'].iloc[-(len(prediction_df)+1):],\n",
    "                                         predictions_df[f'store_pred_{N_HIDDEN}']))\n",
    "        print('\\n','root mean squared error: ')\n",
    "        print((mean_squared_error(predictions_df['store_truth'].iloc[-(len(prediction_df)+1):],\n",
    "                                         predictions_df[f'store_pred_{N_HIDDEN}']))**(1/2)) \n",
    "\n",
    "        iteration_end = time.monotonic()\n",
    "        print('\\n',\"Iteration time: \", iteration_end - iteration_start)\n",
    "\n",
    "        mean_abs_BoRF.append(mean_absolute_scaled_error(predictions_df['store_truth'].iloc[-(len(prediction_df)+1):],\n",
    "                                         predictions_df[f'store_pred_{N_HIDDEN}'],\n",
    "                                         truth_df.iloc[:-len(prediction_df),0]))\n",
    "\n",
    "        mean_sqr_BoRF.append(mean_squared_error(predictions_df['store_truth'].iloc[-(len(prediction_df)+1):],\n",
    "                                         predictions_df[f'store_pred_{N_HIDDEN}'])**(1/2))\n",
    "\n",
    "        time_BoRF.append(iteration_end - iteration_start)\n",
    "\n",
    "    predictions_df.to_csv(f'{folder_path}/Rossmann_LSTM_hidden_BoRF.csv')\n",
    "\n",
    "    %store mean_abs_BoRF\n",
    "    %store mean_sqr_BoRF\n",
    "    %store time_BoRF\n",
    "\n",
    "else:\n",
    "    %store -r mean_abs_BoRF\n",
    "    %store -r mean_sqr_BoRF\n",
    "    %store -r time_BoRF\n",
    "    \n",
    "    print(mean_abs_BoRF)\n",
    "    print(mean_sqr_BoRF)\n",
    "    print(time_BoRF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4addb3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Boruta_SHAPGB == True:\n",
    "    folder_path = 'Predictions/grid_search_BoSHAPGB'\n",
    "    BoSHAPGB_feat = pd.read_csv('Predictions/Single_Run/borutaSHAPGB_df.csv')\n",
    "    \n",
    "    try:\n",
    "        os.mkdir(f'{folder_path}')\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    mean_abs_BoSHAPGB = []\n",
    "    mean_sqr_BoSHAPGB = []\n",
    "    time_BoSHAPGB = []\n",
    "\n",
    "    for N_HIDDEN in hidden_values:\n",
    "        torch.manual_seed(8)\n",
    "        np.random.seed(8)\n",
    "        pl.seed_everything(8);\n",
    "        iteration_start = time.monotonic()\n",
    "\n",
    "        class SalesPredictionModel(nn.Module):\n",
    "            def __init__(self, n_features, n_hidden = N_HIDDEN, n_layers = N_LAYERS):\n",
    "                super().__init__()\n",
    "                self.n_hidden = n_hidden\n",
    "\n",
    "                self.lstm = nn.LSTM(\n",
    "                    input_size = n_features,\n",
    "                    hidden_size = n_hidden,\n",
    "                    batch_first = True,\n",
    "                    num_layers = n_layers,\n",
    "                    dropout = 0.2\n",
    "                )\n",
    "                self.regressor = nn.Linear(n_hidden,1)\n",
    "\n",
    "            def forward(self,x):\n",
    "                self.lstm.flatten_parameters()\n",
    "\n",
    "                _, (hidden, _) = self.lstm(x)\n",
    "                out = hidden[-1]\n",
    "\n",
    "                return self.regressor(out)\n",
    "\n",
    "\n",
    "        class SalesPredictor(pl.LightningModule):\n",
    "\n",
    "            def __init__(self, n_features: int):\n",
    "                super().__init__()\n",
    "                self.model=SalesPredictionModel(n_features)\n",
    "                self.criterion = nn.MSELoss()\n",
    "\n",
    "            def forward(self, x, labels= None):\n",
    "                output = self.model(x)\n",
    "                loss = 0\n",
    "                if labels is not None:\n",
    "                    loss = self.criterion(output, labels.unsqueeze(dim=1))\n",
    "                return loss, output\n",
    "\n",
    "            def training_step(self, batch, batch_index):\n",
    "                sequences = batch['sequence']\n",
    "                labels = batch['label']\n",
    "\n",
    "                loss, outputs = self(sequences, labels)\n",
    "                self.log('train_loss', loss, prog_bar = True, logger=False)\n",
    "                return loss\n",
    "\n",
    "            def validation_step(self, batch, batch_index):\n",
    "                sequences = batch['sequence']\n",
    "                labels = batch['label']\n",
    "\n",
    "                loss, outputs = self(sequences, labels)\n",
    "                self.log('val_loss', loss, prog_bar = True, logger=False)\n",
    "                return loss\n",
    "\n",
    "            def test_step(self, batch, batch_index):\n",
    "                sequences = batch['sequence']\n",
    "                labels = batch['label']\n",
    "\n",
    "                loss, outputs = self(sequences, labels)\n",
    "                self.log('test_loss', loss, prog_bar = True, logger=False)\n",
    "                return loss\n",
    "\n",
    "            def configure_optimizers(self):\n",
    "                return optim.AdamW(self.parameters(), lr = LEARNING)\n",
    "\n",
    "\n",
    "        #makes SHAP calculations for all stores inside the rossmann_treated dataset if removed the [:1]\n",
    "\n",
    "        #to omit outputs\n",
    "        #with io.capture_output() as captured:\n",
    "        df = Rossmann_df.drop(columns  = 'Date')\n",
    "\n",
    "        features = list(BoSHAPGB_feat['important'].fillna(0))\n",
    "\n",
    "        features = [x for x in features if x != 0]\n",
    "\n",
    "        \n",
    "        #return all columns names ('features') except for customers, since it's not an available \n",
    "        #information for future points\n",
    "        features_df = features_dataframe(df,features) \n",
    "        #returns dataframe with the features to be analised\n",
    "\n",
    "        #split into test and train and minmaxscaler\n",
    "        train_df, test_df, train_size =  train_test_spliter(105,features_df)\n",
    "        train_df, test_df, scaler = data_scaler(train_df,test_df)\n",
    "        #make sequences with the data\n",
    "        train_sequences = create_sequences(train_df,TGT,SEQUENCE_LENGTH)\n",
    "        test_sequences = create_sequences (test_df,TGT,SEQUENCE_LENGTH)\n",
    "\n",
    "        #trains the model and store the most recent checkpoints removing previous ones if existing\n",
    "        data_module = SalesDataModule(train_sequences, test_sequences, batch_size = BATCH_SIZE)\n",
    "        data_module.setup()\n",
    "        train_dataset = Dataset(train_sequences)\n",
    "        test_dataset = Dataset(test_sequences)\n",
    "        model = SalesPredictor(n_features = train_df.shape[1])\n",
    "\n",
    "\n",
    "\n",
    "        try:\n",
    "            os.remove(f\"{folder_path}/Checkpoints/Rossmann_LSTM_hidden{N_HIDDEN}_Boruta_SHAPGB.ckpt\")\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        checkpoint_callback = ModelCheckpoint(\n",
    "            dirpath = f'{folder_path}/Checkpoints',\n",
    "            filename = f'Rossmann_LSTM_hidden{N_HIDDEN}_Boruta_SHAPGB',\n",
    "            save_top_k = 1,\n",
    "            verbose = False ,\n",
    "            monitor = 'val_loss',\n",
    "            mode = 'min'\n",
    "        )\n",
    "        logger = TensorBoardLogger('lightning_logs', name = 'btc-price')\n",
    "        early_stopping_callback = EarlyStopping(monitor= 'val_loss', patience = PATIENCE)\n",
    "        trainer = pl.Trainer(\n",
    "            logger = logger,\n",
    "            callbacks=[early_stopping_callback, checkpoint_callback],\n",
    "            max_epochs = N_EPOCHS,\n",
    "            gpus = 0,\n",
    "        )\n",
    "        trainer.fit(model, data_module)\n",
    "\n",
    "        #load the best model from checkpoint\n",
    "        trained_model = SalesPredictor.load_from_checkpoint(\n",
    "        f'{folder_path}/Checkpoints/Rossmann_LSTM_hidden{N_HIDDEN}_Boruta_SHAPGB.ckpt',\n",
    "        n_features = train_df.shape[1]\n",
    "        )\n",
    "\n",
    "        predictions = []\n",
    "        labels = []\n",
    "\n",
    "        for item in test_dataset:\n",
    "            sequence = item['sequence']\n",
    "            label = item['label']\n",
    "\n",
    "            if len(predictions) > SEQUENCE_LENGTH:\n",
    "                for j in range(SEQUENCE_LENGTH):\n",
    "                    sequence[-SEQUENCE_LENGTH+j,0] = float(predictions[-SEQUENCE_LENGTH+j])\n",
    "            else: \n",
    "                for j in range(len(predictions)):\n",
    "                    sequence[-len(predictions)+j,0] = float(predictions[-len(predictions)+j])\n",
    "\n",
    "            _,output = trained_model(sequence.unsqueeze(dim=0))\n",
    "            predictions.append(output.item())\n",
    "            labels.append(label.item())\n",
    "\n",
    "\n",
    "\n",
    "        descaler = MinMaxScaler()\n",
    "        descaler.min_, descaler.scale_ = scaler.min_[0], scaler.scale_[0]\n",
    "\n",
    "        predictions_descaled = descale(descaler,predictions)\n",
    "        labels_descaled = descale(descaler,labels)\n",
    "\n",
    "        test_data = df[train_size+1:]\n",
    "        test_sequences_data = test_data.iloc[SEQUENCE_LENGTH:]\n",
    "\n",
    "        dates = matplotlib.dates.date2num(Rossmann_df.iloc[-len(predictions_descaled):].Date.tolist())\n",
    "        full_dates = matplotlib.dates.date2num(Rossmann_df.Date.tolist())\n",
    "\n",
    "        predictions_descaled = np.where(predictions_descaled<0, 0, predictions_descaled)\n",
    "\n",
    "\n",
    "        dic= {}\n",
    "        dic[f'store_pred_{N_HIDDEN}'] = predictions_descaled\n",
    "        pred_df = pd.DataFrame.from_dict(dic)\n",
    "        pred_df = pred_df.shift(-1)\n",
    "\n",
    "\n",
    "        dic = {}\n",
    "        dic[f'store_pred_dates'] = dates\n",
    "        dic[f'store_truth'] = Rossmann_df[TGT].iloc[-len(pred_df):]\n",
    "        truth_df = pd.DataFrame.from_dict(dic)\n",
    "\n",
    "\n",
    "        if N_HIDDEN != hidden_values[0]:\n",
    "            predictions_df = predictions_df.join(pred_df, how = 'left')\n",
    "        else:\n",
    "            truth_df.reset_index(inplace = True)\n",
    "            truth_df.drop('index', axis=1)\n",
    "            predictions_df = truth_df\n",
    "            predictions_df = predictions_df.join(pred_df, how = 'left')\n",
    "            predictions_df = predictions_df.iloc[:-1]\n",
    "\n",
    "        #display(predictions_df)\n",
    "        \n",
    "        dic = {}\n",
    "        dic[f'store_truth'] = Rossmann_df[TGT]\n",
    "        dic[f'store_truth_dates'] = full_dates\n",
    "        truth_df = pd.DataFrame.from_dict(dic)\n",
    "\n",
    "        dic= {}\n",
    "        dic[f'store_pred'] = predictions_descaled\n",
    "        dic[f'store_pred_dates'] = dates\n",
    "        prediction_df = pd.DataFrame.from_dict(dic)\n",
    "        prediction_df['store_pred'] =prediction_df['store_pred'].shift(-1)\n",
    "        \n",
    "        plt.figure(figsize=(21, 7))\n",
    "        plt.plot_date(truth_df.iloc[-3*len(prediction_df):,1],truth_df.iloc[-3*len(prediction_df):,0],'-', label='Truth')\n",
    "        plt.plot_date(prediction_df.iloc[:,1],prediction_df.iloc[:,0],'-',label ='Prediction')\n",
    "        plt.legend()\n",
    "        plt.show();\n",
    "\n",
    "        print('mean absolute scaled error: ')\n",
    "        print(mean_absolute_scaled_error(predictions_df['store_truth'].iloc[-(len(prediction_df)+1):],\n",
    "                                         predictions_df[f'store_pred_{N_HIDDEN}'],\n",
    "                                         truth_df.iloc[:-len(prediction_df),0]))\n",
    "        print('\\n','mean squared error: ')\n",
    "        print(mean_squared_error(predictions_df['store_truth'].iloc[-(len(prediction_df)+1):],\n",
    "                                         predictions_df[f'store_pred_{N_HIDDEN}']))\n",
    "        print('\\n','root mean squared error: ')\n",
    "        print((mean_squared_error(predictions_df['store_truth'].iloc[-(len(prediction_df)+1):],\n",
    "                                         predictions_df[f'store_pred_{N_HIDDEN}']))**(1/2)) \n",
    "\n",
    "        iteration_end = time.monotonic()\n",
    "        print('\\n',\"Iteration time: \", iteration_end - iteration_start)\n",
    "\n",
    "        mean_abs_BoSHAPGB.append(mean_absolute_scaled_error(predictions_df['store_truth'].iloc[-(len(prediction_df)+1):],\n",
    "                                         predictions_df[f'store_pred_{N_HIDDEN}'],\n",
    "                                         truth_df.iloc[:-len(prediction_df),0]))\n",
    "\n",
    "        mean_sqr_BoSHAPGB.append(mean_squared_error(predictions_df['store_truth'].iloc[-(len(prediction_df)+1):],\n",
    "                                         predictions_df[f'store_pred_{N_HIDDEN}'])**(1/2))\n",
    "\n",
    "        time_BoSHAPGB.append(iteration_end - iteration_start)\n",
    "\n",
    "    predictions_df.to_csv(f'{folder_path}/Rossmann_LSTM_hidden_BoSHAPGB.csv')\n",
    "\n",
    "    %store mean_abs_BoSHAPGB\n",
    "    %store mean_sqr_BoSHAPGB\n",
    "    %store time_BoSHAPGB\n",
    "\n",
    "else:\n",
    "    %store -r mean_abs_BoSHAPGB\n",
    "    %store -r mean_sqr_BoSHAPGB\n",
    "    %store -r time_BoSHAPGB\n",
    "    \n",
    "    print(mean_abs_BoSHAPGB)\n",
    "    print(mean_sqr_BoSHAPGB)\n",
    "    print(time_BoSHAPGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d3ece3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Boruta_SHAPRF == True:\n",
    "    folder_path = 'Predictions/grid_search_BoSHAPRF'\n",
    "    BoSHAPRF_feat = pd.read_csv('Predictions/Single_Run/borutaSHAPRF_df.csv')\n",
    "    \n",
    "    try:\n",
    "        os.mkdir(f'{folder_path}')\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    mean_abs_BoSHAPRF = []\n",
    "    mean_sqr_BoSHAPRF = []\n",
    "    time_BoSHAPRF = []\n",
    "\n",
    "    for N_HIDDEN in hidden_values:\n",
    "        torch.manual_seed(8)\n",
    "        np.random.seed(8)\n",
    "        pl.seed_everything(8);\n",
    "        iteration_start = time.monotonic()\n",
    "        \n",
    "        class SalesPredictionModel(nn.Module):\n",
    "            def __init__(self, n_features, n_hidden = N_HIDDEN, n_layers = N_LAYERS):\n",
    "                super().__init__()\n",
    "                self.n_hidden = n_hidden\n",
    "\n",
    "                self.lstm = nn.LSTM(\n",
    "                    input_size = n_features,\n",
    "                    hidden_size = n_hidden,\n",
    "                    batch_first = True,\n",
    "                    num_layers = n_layers,\n",
    "                    dropout = 0.2\n",
    "                )\n",
    "                self.regressor = nn.Linear(n_hidden,1)\n",
    "\n",
    "            def forward(self,x):\n",
    "                self.lstm.flatten_parameters()\n",
    "\n",
    "                _, (hidden, _) = self.lstm(x)\n",
    "                out = hidden[-1]\n",
    "\n",
    "                return self.regressor(out)\n",
    "\n",
    "\n",
    "        class SalesPredictor(pl.LightningModule):\n",
    "\n",
    "            def __init__(self, n_features: int):\n",
    "                super().__init__()\n",
    "                self.model=SalesPredictionModel(n_features)\n",
    "                self.criterion = nn.MSELoss()\n",
    "\n",
    "            def forward(self, x, labels= None):\n",
    "                output = self.model(x)\n",
    "                loss = 0\n",
    "                if labels is not None:\n",
    "                    loss = self.criterion(output, labels.unsqueeze(dim=1))\n",
    "                return loss, output\n",
    "\n",
    "            def training_step(self, batch, batch_index):\n",
    "                sequences = batch['sequence']\n",
    "                labels = batch['label']\n",
    "\n",
    "                loss, outputs = self(sequences, labels)\n",
    "                self.log('train_loss', loss, prog_bar = True, logger=False)\n",
    "                return loss\n",
    "\n",
    "            def validation_step(self, batch, batch_index):\n",
    "                sequences = batch['sequence']\n",
    "                labels = batch['label']\n",
    "\n",
    "                loss, outputs = self(sequences, labels)\n",
    "                self.log('val_loss', loss, prog_bar = True, logger=False)\n",
    "                return loss\n",
    "\n",
    "            def test_step(self, batch, batch_index):\n",
    "                sequences = batch['sequence']\n",
    "                labels = batch['label']\n",
    "\n",
    "                loss, outputs = self(sequences, labels)\n",
    "                self.log('test_loss', loss, prog_bar = True, logger=False)\n",
    "                return loss\n",
    "\n",
    "            def configure_optimizers(self):\n",
    "                return optim.AdamW(self.parameters(), lr = LEARNING)\n",
    "\n",
    "\n",
    "        #makes SHAP calculations for all stores inside the rossmann_treated dataset if removed the [:1]\n",
    "\n",
    "        #to omit outputs\n",
    "        #with io.capture_output() as captured:\n",
    "        df = Rossmann_df.drop(columns  = 'Date')\n",
    "\n",
    "        features = list(BoSHAPRF_feat['important'].fillna(0))\n",
    "\n",
    "        features = [x for x in features if x != 0]\n",
    "\n",
    "        #return all columns names ('features') except for customers, since it's not an available \n",
    "        #information for future points\n",
    "        features_df = features_dataframe(df,features) \n",
    "        #returns dataframe with the features to be analised\n",
    "\n",
    "        #split into test and train and minmaxscaler\n",
    "        train_df, test_df, train_size =  train_test_spliter(105,features_df)\n",
    "        train_df, test_df, scaler = data_scaler(train_df,test_df)\n",
    "        #make sequences with the data\n",
    "        train_sequences = create_sequences(train_df,TGT,SEQUENCE_LENGTH)\n",
    "        test_sequences = create_sequences (test_df,TGT,SEQUENCE_LENGTH)\n",
    "\n",
    "        #trains the model and store the most recent checkpoints removing previous ones if existing\n",
    "        data_module = SalesDataModule(train_sequences, test_sequences, batch_size = BATCH_SIZE)\n",
    "        data_module.setup()\n",
    "        train_dataset = Dataset(train_sequences)\n",
    "        test_dataset = Dataset(test_sequences)\n",
    "        model = SalesPredictor(n_features = train_df.shape[1])\n",
    "\n",
    "\n",
    "\n",
    "        try:\n",
    "            os.remove(f\"{folder_path}/Checkpoints/Rossmann_LSTM_hidden{N_HIDDEN}_Boruta_SHAPRF.ckpt\")\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        checkpoint_callback = ModelCheckpoint(\n",
    "            dirpath = f'{folder_path}/Checkpoints',\n",
    "            filename = f'Rossmann_LSTM_hidden{N_HIDDEN}_Boruta_SHAPRF',\n",
    "            save_top_k = 1,\n",
    "            verbose = False ,\n",
    "            monitor = 'val_loss',\n",
    "            mode = 'min'\n",
    "        )\n",
    "        logger = TensorBoardLogger('lightning_logs', name = 'btc-price')\n",
    "        early_stopping_callback = EarlyStopping(monitor= 'val_loss', patience = PATIENCE)\n",
    "        trainer = pl.Trainer(\n",
    "            logger = logger,\n",
    "            callbacks=[early_stopping_callback, checkpoint_callback],\n",
    "            max_epochs = N_EPOCHS,\n",
    "            gpus = 0,\n",
    "        )\n",
    "        trainer.fit(model, data_module)\n",
    "\n",
    "        #load the best model from checkpoint\n",
    "        trained_model = SalesPredictor.load_from_checkpoint(\n",
    "        f'{folder_path}/Checkpoints/Rossmann_LSTM_hidden{N_HIDDEN}_Boruta_SHAPRF.ckpt',\n",
    "        n_features = train_df.shape[1]\n",
    "        )\n",
    "\n",
    "        predictions = []\n",
    "        labels = []\n",
    "\n",
    "        for item in test_dataset:\n",
    "            sequence = item['sequence']\n",
    "            label = item['label']\n",
    "\n",
    "            if len(predictions) > SEQUENCE_LENGTH:\n",
    "                for j in range(SEQUENCE_LENGTH):\n",
    "                    sequence[-SEQUENCE_LENGTH+j,0] = float(predictions[-SEQUENCE_LENGTH+j])\n",
    "            else: \n",
    "                for j in range(len(predictions)):\n",
    "                    sequence[-len(predictions)+j,0] = float(predictions[-len(predictions)+j])\n",
    "\n",
    "            _,output = trained_model(sequence.unsqueeze(dim=0))\n",
    "            predictions.append(output.item())\n",
    "            labels.append(label.item())\n",
    "\n",
    "\n",
    "\n",
    "        descaler = MinMaxScaler()\n",
    "        descaler.min_, descaler.scale_ = scaler.min_[0], scaler.scale_[0]\n",
    "\n",
    "        predictions_descaled = descale(descaler,predictions)\n",
    "        labels_descaled = descale(descaler,labels)\n",
    "\n",
    "        test_data = df[train_size+1:]\n",
    "        test_sequences_data = test_data.iloc[SEQUENCE_LENGTH:]\n",
    "\n",
    "        dates = matplotlib.dates.date2num(Rossmann_df.iloc[-len(predictions_descaled):].Date.tolist())\n",
    "        full_dates = matplotlib.dates.date2num(Rossmann_df.Date.tolist())\n",
    "\n",
    "        predictions_descaled = np.where(predictions_descaled<0, 0, predictions_descaled)\n",
    "\n",
    "\n",
    "        dic= {}\n",
    "        dic[f'store_pred_{N_HIDDEN}'] = predictions_descaled\n",
    "        pred_df = pd.DataFrame.from_dict(dic)\n",
    "        pred_df = pred_df.shift(-1)\n",
    "\n",
    "\n",
    "        dic = {}\n",
    "        dic[f'store_pred_dates'] = dates\n",
    "        dic[f'store_truth'] = Rossmann_df[TGT].iloc[-len(pred_df):]\n",
    "        truth_df = pd.DataFrame.from_dict(dic)\n",
    "\n",
    "\n",
    "        if N_HIDDEN != hidden_values[0]:\n",
    "            predictions_df = predictions_df.join(pred_df, how = 'left')\n",
    "        else:\n",
    "            truth_df.reset_index(inplace = True)\n",
    "            truth_df.drop('index', axis=1)\n",
    "            predictions_df = truth_df\n",
    "            predictions_df = predictions_df.join(pred_df, how = 'left')\n",
    "            predictions_df = predictions_df.iloc[:-1]\n",
    "\n",
    "        #display(predictions_df)\n",
    "        \n",
    "        dic = {}\n",
    "        dic[f'store_truth'] = Rossmann_df[TGT]\n",
    "        dic[f'store_truth_dates'] = full_dates\n",
    "        truth_df = pd.DataFrame.from_dict(dic)\n",
    "\n",
    "        dic= {}\n",
    "        dic[f'store_pred'] = predictions_descaled\n",
    "        dic[f'store_pred_dates'] = dates\n",
    "        prediction_df = pd.DataFrame.from_dict(dic)\n",
    "        prediction_df['store_pred'] =prediction_df['store_pred'].shift(-1)\n",
    "        \n",
    "        plt.figure(figsize=(21, 7))\n",
    "        plt.plot_date(truth_df.iloc[-3*len(prediction_df):,1],truth_df.iloc[-3*len(prediction_df):,0],'-', label='Truth')\n",
    "        plt.plot_date(prediction_df.iloc[:,1],prediction_df.iloc[:,0],'-',label ='Prediction')\n",
    "        plt.legend()\n",
    "        plt.show();\n",
    "\n",
    "        print('mean absolute scaled error: ')\n",
    "        print(mean_absolute_scaled_error(predictions_df['store_truth'].iloc[-(len(prediction_df)+1):],\n",
    "                                         predictions_df[f'store_pred_{N_HIDDEN}'],\n",
    "                                         truth_df.iloc[:-len(prediction_df),0]))\n",
    "        print('\\n','mean squared error: ')\n",
    "        print(mean_squared_error(predictions_df['store_truth'].iloc[-(len(prediction_df)+1):],\n",
    "                                         predictions_df[f'store_pred_{N_HIDDEN}']))\n",
    "        print('\\n','root mean squared error: ')\n",
    "        print((mean_squared_error(predictions_df['store_truth'].iloc[-(len(prediction_df)+1):],\n",
    "                                         predictions_df[f'store_pred_{N_HIDDEN}']))**(1/2)) \n",
    "\n",
    "        iteration_end = time.monotonic()\n",
    "        print('\\n',\"Iteration time: \", iteration_end - iteration_start)\n",
    "\n",
    "        mean_abs_BoSHAPRF.append(mean_absolute_scaled_error(predictions_df['store_truth'].iloc[-(len(prediction_df)+1):],\n",
    "                                         predictions_df[f'store_pred_{N_HIDDEN}'],\n",
    "                                         truth_df.iloc[:-len(prediction_df),0]))\n",
    "\n",
    "        mean_sqr_BoSHAPRF.append(mean_squared_error(predictions_df['store_truth'].iloc[-(len(prediction_df)+1):],\n",
    "                                         predictions_df[f'store_pred_{N_HIDDEN}'])**(1/2))\n",
    "\n",
    "        time_BoSHAPRF.append(iteration_end - iteration_start)\n",
    "\n",
    "    predictions_df.to_csv(f'{folder_path}/Rossmann_LSTM_hidden_BoSHAPRF.csv')\n",
    "\n",
    "    %store mean_abs_BoSHAPRF\n",
    "    %store mean_sqr_BoSHAPRF\n",
    "    %store time_BoSHAPRF\n",
    "\n",
    "else:\n",
    "    %store -r mean_abs_BoSHAPRF\n",
    "    %store -r mean_sqr_BoSHAPRF\n",
    "    %store -r time_BoSHAPRF\n",
    "    \n",
    "    print(mean_abs_BoSHAPRF)\n",
    "    print(mean_sqr_BoSHAPRF)\n",
    "    print(time_BoSHAPRF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ccc146",
   "metadata": {},
   "outputs": [],
   "source": [
    "if LIME_train == True:\n",
    "    folder_path = 'Predictions/grid_search_LIME'\n",
    "\n",
    "    LIME_inst_th = [0.007,0.008,0.009,0.01]\n",
    "    inst_LSTMLIME= pd.read_csv('Predictions/Single_Run/Features_LSTMLIME.csv')\n",
    "    LIME_inst_dic = {}\n",
    "\n",
    "\n",
    "    try:\n",
    "        os.mkdir(f'{folder_path}')\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    for LIME_th in LIME_inst_th:\n",
    "        mean_abs_LIME_inst = []\n",
    "        mean_sqr_LIME_inst = []\n",
    "        time_LIME_inst = []\n",
    "\n",
    "        for N_HIDDEN in hidden_values:\n",
    "            torch.manual_seed(8)\n",
    "            np.random.seed(8)\n",
    "            pl.seed_everything(8);\n",
    "            iteration_start = time.monotonic()\n",
    "\n",
    "            hidden_dic = {}\n",
    "\n",
    "            class SalesPredictionModel(nn.Module):\n",
    "                def __init__(self, n_features, n_hidden = N_HIDDEN, n_layers = N_LAYERS):\n",
    "                    super().__init__()\n",
    "                    self.n_hidden = n_hidden\n",
    "\n",
    "                    self.lstm = nn.LSTM(\n",
    "                        input_size = n_features,\n",
    "                        hidden_size = n_hidden,\n",
    "                        batch_first = True,\n",
    "                        num_layers = n_layers,\n",
    "                        dropout = 0.2\n",
    "                    )\n",
    "                    self.regressor = nn.Linear(n_hidden,1)\n",
    "\n",
    "                def forward(self,x):\n",
    "                    self.lstm.flatten_parameters()\n",
    "\n",
    "                    _, (hidden, _) = self.lstm(x)\n",
    "                    out = hidden[-1]\n",
    "\n",
    "                    return self.regressor(out)\n",
    "\n",
    "\n",
    "            class SalesPredictor(pl.LightningModule):\n",
    "\n",
    "                def __init__(self, n_features: int):\n",
    "                    super().__init__()\n",
    "                    self.model=SalesPredictionModel(n_features)\n",
    "                    self.criterion = nn.MSELoss()\n",
    "\n",
    "                def forward(self, x, labels= None):\n",
    "                    output = self.model(x)\n",
    "                    loss = 0\n",
    "                    if labels is not None:\n",
    "                        loss = self.criterion(output, labels.unsqueeze(dim=1))\n",
    "                    return loss, output\n",
    "\n",
    "                def training_step(self, batch, batch_index):\n",
    "                    sequences = batch['sequence']\n",
    "                    labels = batch['label']\n",
    "\n",
    "                    loss, outputs = self(sequences, labels)\n",
    "                    self.log('train_loss', loss, prog_bar = True, logger=False)\n",
    "                    return loss\n",
    "\n",
    "                def validation_step(self, batch, batch_index):\n",
    "                    sequences = batch['sequence']\n",
    "                    labels = batch['label']\n",
    "\n",
    "                    loss, outputs = self(sequences, labels)\n",
    "                    self.log('val_loss', loss, prog_bar = True, logger=False)\n",
    "                    return loss\n",
    "\n",
    "                def test_step(self, batch, batch_index):\n",
    "                    sequences = batch['sequence']\n",
    "                    labels = batch['label']\n",
    "\n",
    "                    loss, outputs = self(sequences, labels)\n",
    "                    self.log('test_loss', loss, prog_bar = True, logger=False)\n",
    "                    return loss\n",
    "\n",
    "                def configure_optimizers(self):\n",
    "                    return optim.AdamW(self.parameters(), lr = LEARNING)\n",
    "\n",
    "\n",
    "            #makes SHAP calculations for all stores inside the rossmann_treated dataset if removed the [:1]\n",
    "\n",
    "            #to omit outputs\n",
    "            #with io.capture_output() as captured:\n",
    "            df = Rossmann_df.drop(columns  = 'Date')\n",
    "            features = list(inst_LSTMLIME['features'].loc[inst_LSTMLIME['LIME_value'] > LIME_th])\n",
    "\n",
    "            #return all columns names ('features') except for customers, since it's not an available \n",
    "            #information for future points\n",
    "            features_df = features_dataframe(df,features) \n",
    "            #returns dataframe with the features to be analised\n",
    "\n",
    "            #split into test and train and minmaxscaler\n",
    "            train_df, test_df, train_size =  train_test_spliter(105,features_df)\n",
    "            train_df, test_df, scaler = data_scaler(train_df,test_df)\n",
    "            #make sequences with the data\n",
    "            train_sequences = create_sequences(train_df,TGT,SEQUENCE_LENGTH)\n",
    "            test_sequences = create_sequences (test_df,TGT,SEQUENCE_LENGTH)\n",
    "\n",
    "            #trains the model and store the most recent checkpoints removing previous ones if existing\n",
    "            data_module = SalesDataModule(train_sequences, test_sequences, batch_size = BATCH_SIZE)\n",
    "            data_module.setup()\n",
    "            train_dataset = Dataset(train_sequences)\n",
    "            test_dataset = Dataset(test_sequences)\n",
    "            model = SalesPredictor(n_features = train_df.shape[1])\n",
    "\n",
    "\n",
    "\n",
    "            try:\n",
    "                os.remove(f\"{folder_path}/Checkpoints/Rossmann_LSTM_hidden{N_HIDDEN}_LIME{LIME_th}.ckpt\")\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            checkpoint_callback = ModelCheckpoint(\n",
    "                dirpath = f'{folder_path}/Checkpoints',\n",
    "                filename = f'Rossmann_LSTM_hidden{N_HIDDEN}_LIME{LIME_th}',\n",
    "                save_top_k = 1,\n",
    "                verbose = False ,\n",
    "                monitor = 'val_loss',\n",
    "                mode = 'min'\n",
    "            )\n",
    "            logger = TensorBoardLogger('lightning_logs', name = 'btc-price')\n",
    "            early_stopping_callback = EarlyStopping(monitor= 'val_loss', patience = PATIENCE)\n",
    "            trainer = pl.Trainer(\n",
    "                logger = logger,\n",
    "                callbacks=[early_stopping_callback, checkpoint_callback],\n",
    "                max_epochs = N_EPOCHS,\n",
    "                gpus = 0,\n",
    "            )\n",
    "            trainer.fit(model, data_module)\n",
    "\n",
    "            #load the best model from checkpoint\n",
    "            trained_model = SalesPredictor.load_from_checkpoint(\n",
    "            f'{folder_path}/Checkpoints/Rossmann_LSTM_hidden{N_HIDDEN}_LIME{LIME_th}.ckpt',\n",
    "            n_features = train_df.shape[1]\n",
    "            )\n",
    "\n",
    "            predictions = []\n",
    "            labels = []\n",
    "\n",
    "            for item in test_dataset:\n",
    "                sequence = item['sequence']\n",
    "                label = item['label']\n",
    "\n",
    "                if len(predictions) > SEQUENCE_LENGTH:\n",
    "                    for j in range(SEQUENCE_LENGTH):\n",
    "                        sequence[-SEQUENCE_LENGTH+j,0] = float(predictions[-SEQUENCE_LENGTH+j])\n",
    "                else: \n",
    "                    for j in range(len(predictions)):\n",
    "                        sequence[-len(predictions)+j,0] = float(predictions[-len(predictions)+j])\n",
    "\n",
    "                _,output = trained_model(sequence.unsqueeze(dim=0))\n",
    "                predictions.append(output.item())\n",
    "                labels.append(label.item())\n",
    "\n",
    "\n",
    "\n",
    "            descaler = MinMaxScaler()\n",
    "            descaler.min_, descaler.scale_ = scaler.min_[0], scaler.scale_[0]\n",
    "\n",
    "            predictions_descaled = descale(descaler,predictions)\n",
    "            labels_descaled = descale(descaler,labels)\n",
    "\n",
    "            test_data = df[train_size+1:]\n",
    "            test_sequences_data = test_data.iloc[SEQUENCE_LENGTH:]\n",
    "\n",
    "            dates = matplotlib.dates.date2num(Rossmann_df.iloc[-len(predictions_descaled):].Date.tolist())\n",
    "            full_dates = matplotlib.dates.date2num(Rossmann_df.Date.tolist())\n",
    "\n",
    "            dic= {}\n",
    "            dic[f'store_pred_{N_HIDDEN}'] = predictions_descaled\n",
    "            pred_df = pd.DataFrame.from_dict(dic)\n",
    "            pred_df = pred_df.shift(-1)\n",
    "\n",
    "\n",
    "            dic = {}\n",
    "            dic[f'store_pred_dates'] = dates\n",
    "            dic[f'store_truth'] = Rossmann_df[TGT].iloc[-len(pred_df):]\n",
    "            truth_df = pd.DataFrame.from_dict(dic)\n",
    "\n",
    "            if N_HIDDEN != hidden_values[0]:\n",
    "                predictions_df = predictions_df.join(pred_df, how = 'left')\n",
    "            else:\n",
    "                truth_df.reset_index(inplace = True)\n",
    "                truth_df.drop('index', axis=1)\n",
    "                predictions_df = truth_df\n",
    "                predictions_df = predictions_df.join(pred_df, how = 'left')\n",
    "                predictions_df = predictions_df.iloc[:-1]\n",
    "\n",
    "            display(predictions_df)\n",
    "\n",
    "            dic = {}\n",
    "            dic[f'store_truth'] = Rossmann_df[TGT]\n",
    "            dic[f'store_truth_dates'] = full_dates\n",
    "            truth_df = pd.DataFrame.from_dict(dic)\n",
    "\n",
    "            dic= {}\n",
    "            dic[f'store_pred'] = predictions_descaled\n",
    "            dic[f'store_pred_dates'] = dates\n",
    "            prediction_df = pd.DataFrame.from_dict(dic)\n",
    "            prediction_df['store_pred'] =prediction_df['store_pred'].shift(-1)\n",
    "\n",
    "            plt.figure(figsize=(21, 7))\n",
    "            plt.plot_date(truth_df.iloc[-3*len(prediction_df):,1],truth_df.iloc[-3*len(prediction_df):,0],'-', label='Truth')\n",
    "            plt.plot_date(prediction_df.iloc[:,1],prediction_df.iloc[:,0],'-',label ='Prediction')\n",
    "            plt.legend()\n",
    "            plt.show();\n",
    "\n",
    "            iteration_end = time.monotonic()\n",
    "\n",
    "            predictions_descaled = np.where(predictions_descaled<0, 0, predictions_descaled)\n",
    "\n",
    "            mean_abs_LIME_inst.append(mean_absolute_scaled_error(predictions_df['store_truth'].iloc[-(len(prediction_df)+1):],\n",
    "                                             predictions_df[f'store_pred_{N_HIDDEN}'],\n",
    "                                             truth_df.iloc[:-len(prediction_df),0]))\n",
    "\n",
    "            mean_sqr_LIME_inst.append(mean_squared_error(predictions_df['store_truth'].iloc[-(len(prediction_df)+1):],\n",
    "                                             predictions_df[f'store_pred_{N_HIDDEN}'])**(1/2))\n",
    "\n",
    "            time_LIME_inst.append(iteration_end - iteration_start)\n",
    "\n",
    "            hidden_dic['mase'] = mean_abs_LIME_inst\n",
    "            hidden_dic['mse']  = mean_sqr_LIME_inst\n",
    "            hidden_dic['time'] = time_LIME_inst\n",
    "            \n",
    "            print(LIME_th)\n",
    "            print(N_HIDDEN)\n",
    "            print(hidden_dic)\n",
    "        LIME_inst_dic[LIME_th] = hidden_dic\n",
    "        \n",
    "    #predictions_df.to_csv(f'{folder_path}/Rossmann_LSTM_LIME.csv')\n",
    "    \n",
    "    %store LIME_inst_dic\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "            dic = {}\n",
    "            dic[f'store_truth'] = Rossmann_df[TGT]\n",
    "            dic[f'store_truth_dates'] = full_dates\n",
    "            truth_df = pd.DataFrame.from_dict(dic)\n",
    "\n",
    "            dic= {}\n",
    "            dic[f'store_pred'] = predictions_descaled\n",
    "            dic[f'store_pred_dates'] = dates\n",
    "            prediction_df = pd.DataFrame.from_dict(dic)\n",
    "            prediction_df.to_csv(f'{folder_path}/Rossmann_LSTM_hidden{N_HIDDEN}.csv')\n",
    "\n",
    "            plt.plot_date(truth_df.iloc[-3*len(prediction_df):,1],truth_df.iloc[-3*len(prediction_df):,0],'-', label='Truth')\n",
    "            plt.plot_date(prediction_df.iloc[:,1],prediction_df.iloc[:,0],'-',label ='Prediction')\n",
    "            plt.legend()\n",
    "            plt.show();\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3df775c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if SHAP_insta == True:\n",
    "    folder_path = 'Predictions/grid_search_SHAP_inst'\n",
    "\n",
    "    SHAP_inst_th = [0.05,0.1,0.15,0.2]\n",
    "    inst_LSTMSHAP= pd.read_csv('Predictions/Single_Run/Features_inst_LSTMSHAP.csv')\n",
    "    SHAP_inst_dic = {}\n",
    "\n",
    "\n",
    "    try:\n",
    "        os.mkdir(f'{folder_path}')\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    for SHAP_th in SHAP_inst_th:\n",
    "        mean_abs_SHAP_inst = []\n",
    "        mean_sqr_SHAP_inst = []\n",
    "        time_SHAP_inst = []\n",
    "\n",
    "        for N_HIDDEN in hidden_values:\n",
    "            torch.manual_seed(8)\n",
    "            np.random.seed(8)\n",
    "            pl.seed_everything(8);\n",
    "            iteration_start = time.monotonic()\n",
    "\n",
    "            hidden_dic = {}\n",
    "\n",
    "            class SalesPredictionModel(nn.Module):\n",
    "                def __init__(self, n_features, n_hidden = N_HIDDEN, n_layers = N_LAYERS):\n",
    "                    super().__init__()\n",
    "                    self.n_hidden = n_hidden\n",
    "\n",
    "                    self.lstm = nn.LSTM(\n",
    "                        input_size = n_features,\n",
    "                        hidden_size = n_hidden,\n",
    "                        batch_first = True,\n",
    "                        num_layers = n_layers,\n",
    "                        dropout = 0.2\n",
    "                    )\n",
    "                    self.regressor = nn.Linear(n_hidden,1)\n",
    "\n",
    "                def forward(self,x):\n",
    "                    self.lstm.flatten_parameters()\n",
    "\n",
    "                    _, (hidden, _) = self.lstm(x)\n",
    "                    out = hidden[-1]\n",
    "\n",
    "                    return self.regressor(out)\n",
    "\n",
    "\n",
    "            class SalesPredictor(pl.LightningModule):\n",
    "\n",
    "                def __init__(self, n_features: int):\n",
    "                    super().__init__()\n",
    "                    self.model=SalesPredictionModel(n_features)\n",
    "                    self.criterion = nn.MSELoss()\n",
    "\n",
    "                def forward(self, x, labels= None):\n",
    "                    output = self.model(x)\n",
    "                    loss = 0\n",
    "                    if labels is not None:\n",
    "                        loss = self.criterion(output, labels.unsqueeze(dim=1))\n",
    "                    return loss, output\n",
    "\n",
    "                def training_step(self, batch, batch_index):\n",
    "                    sequences = batch['sequence']\n",
    "                    labels = batch['label']\n",
    "\n",
    "                    loss, outputs = self(sequences, labels)\n",
    "                    self.log('train_loss', loss, prog_bar = True, logger=False)\n",
    "                    return loss\n",
    "\n",
    "                def validation_step(self, batch, batch_index):\n",
    "                    sequences = batch['sequence']\n",
    "                    labels = batch['label']\n",
    "\n",
    "                    loss, outputs = self(sequences, labels)\n",
    "                    self.log('val_loss', loss, prog_bar = True, logger=False)\n",
    "                    return loss\n",
    "\n",
    "                def test_step(self, batch, batch_index):\n",
    "                    sequences = batch['sequence']\n",
    "                    labels = batch['label']\n",
    "\n",
    "                    loss, outputs = self(sequences, labels)\n",
    "                    self.log('test_loss', loss, prog_bar = True, logger=False)\n",
    "                    return loss\n",
    "\n",
    "                def configure_optimizers(self):\n",
    "                    return optim.AdamW(self.parameters(), lr = LEARNING)\n",
    "\n",
    "\n",
    "            #makes SHAP calculations for all stores inside the rossmann_treated dataset if removed the [:1]\n",
    "\n",
    "            #to omit outputs\n",
    "            #with io.capture_output() as captured:\n",
    "            df = Rossmann_df.drop(columns  = 'Date')\n",
    "            features = list(inst_LSTMSHAP['feature_name'].loc[inst_LSTMSHAP['shap_value'] > SHAP_th])\n",
    "\n",
    "            #return all columns names ('features') except for customers, since it's not an available \n",
    "            #information for future points\n",
    "            features_df = features_dataframe(df,features) \n",
    "            #returns dataframe with the features to be analised\n",
    "\n",
    "            #split into test and train and minmaxscaler\n",
    "            train_df, test_df, train_size =  train_test_spliter(105,features_df)\n",
    "            train_df, test_df, scaler = data_scaler(train_df,test_df)\n",
    "            #make sequences with the data\n",
    "            train_sequences = create_sequences(train_df,TGT,SEQUENCE_LENGTH)\n",
    "            test_sequences = create_sequences (test_df,TGT,SEQUENCE_LENGTH)\n",
    "\n",
    "            #trains the model and store the most recent checkpoints removing previous ones if existing\n",
    "            data_module = SalesDataModule(train_sequences, test_sequences, batch_size = BATCH_SIZE)\n",
    "            data_module.setup()\n",
    "            train_dataset = Dataset(train_sequences)\n",
    "            test_dataset = Dataset(test_sequences)\n",
    "            model = SalesPredictor(n_features = train_df.shape[1])\n",
    "\n",
    "\n",
    "\n",
    "            try:\n",
    "                os.remove(f\"{folder_path}/Checkpoints/Rossmann_LSTM_hidden{N_HIDDEN}_SHAPins{SHAP_th}.ckpt\")\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            checkpoint_callback = ModelCheckpoint(\n",
    "                dirpath = f'{folder_path}/Checkpoints',\n",
    "                filename = f'Rossmann_LSTM_hidden{N_HIDDEN}_SHAPins{SHAP_th}',\n",
    "                save_top_k = 1,\n",
    "                verbose = False ,\n",
    "                monitor = 'val_loss',\n",
    "                mode = 'min'\n",
    "            )\n",
    "            logger = TensorBoardLogger('lightning_logs', name = 'btc-price')\n",
    "            early_stopping_callback = EarlyStopping(monitor= 'val_loss', patience = PATIENCE)\n",
    "            trainer = pl.Trainer(\n",
    "                logger = logger,\n",
    "                callbacks=[early_stopping_callback, checkpoint_callback],\n",
    "                max_epochs = N_EPOCHS,\n",
    "                gpus = 0,\n",
    "            )\n",
    "            trainer.fit(model, data_module)\n",
    "\n",
    "            #load the best model from checkpoint\n",
    "            trained_model = SalesPredictor.load_from_checkpoint(\n",
    "            f'{folder_path}/Checkpoints/Rossmann_LSTM_hidden{N_HIDDEN}_SHAPins{SHAP_th}.ckpt',\n",
    "            n_features = train_df.shape[1]\n",
    "            )\n",
    "\n",
    "            predictions = []\n",
    "            labels = []\n",
    "\n",
    "            for item in test_dataset:\n",
    "                sequence = item['sequence']\n",
    "                label = item['label']\n",
    "\n",
    "                if len(predictions) > SEQUENCE_LENGTH:\n",
    "                    for j in range(SEQUENCE_LENGTH):\n",
    "                        sequence[-SEQUENCE_LENGTH+j,0] = float(predictions[-SEQUENCE_LENGTH+j])\n",
    "                else: \n",
    "                    for j in range(len(predictions)):\n",
    "                        sequence[-len(predictions)+j,0] = float(predictions[-len(predictions)+j])\n",
    "\n",
    "                _,output = trained_model(sequence.unsqueeze(dim=0))\n",
    "                predictions.append(output.item())\n",
    "                labels.append(label.item())\n",
    "\n",
    "\n",
    "\n",
    "            descaler = MinMaxScaler()\n",
    "            descaler.min_, descaler.scale_ = scaler.min_[0], scaler.scale_[0]\n",
    "\n",
    "            predictions_descaled = descale(descaler,predictions)\n",
    "            labels_descaled = descale(descaler,labels)\n",
    "\n",
    "            test_data = df[train_size+1:]\n",
    "            test_sequences_data = test_data.iloc[SEQUENCE_LENGTH:]\n",
    "\n",
    "            dates = matplotlib.dates.date2num(Rossmann_df.iloc[-len(predictions_descaled):].Date.tolist())\n",
    "            full_dates = matplotlib.dates.date2num(Rossmann_df.Date.tolist())\n",
    "\n",
    "            dic= {}\n",
    "            dic[f'store_pred_{N_HIDDEN}'] = predictions_descaled\n",
    "            pred_df = pd.DataFrame.from_dict(dic)\n",
    "            pred_df = pred_df.shift(-1)\n",
    "\n",
    "\n",
    "            dic = {}\n",
    "            dic[f'store_pred_dates'] = dates\n",
    "            dic[f'store_truth'] = Rossmann_df[TGT].iloc[-len(pred_df):]\n",
    "            truth_df = pd.DataFrame.from_dict(dic)\n",
    "\n",
    "            if N_HIDDEN != hidden_values[0]:\n",
    "                predictions_df = predictions_df.join(pred_df, how = 'left')\n",
    "            else:\n",
    "                truth_df.reset_index(inplace = True)\n",
    "                truth_df.drop('index', axis=1)\n",
    "                predictions_df = truth_df\n",
    "                predictions_df = predictions_df.join(pred_df, how = 'left')\n",
    "                predictions_df = predictions_df.iloc[:-1]\n",
    "\n",
    "            display(predictions_df)\n",
    "\n",
    "            dic = {}\n",
    "            dic[f'store_truth'] = Rossmann_df[TGT]\n",
    "            dic[f'store_truth_dates'] = full_dates\n",
    "            truth_df = pd.DataFrame.from_dict(dic)\n",
    "\n",
    "            dic= {}\n",
    "            dic[f'store_pred'] = predictions_descaled\n",
    "            dic[f'store_pred_dates'] = dates\n",
    "            prediction_df = pd.DataFrame.from_dict(dic)\n",
    "            prediction_df['store_pred'] =prediction_df['store_pred'].shift(-1)\n",
    "\n",
    "            plt.figure(figsize=(21, 7))\n",
    "            plt.plot_date(truth_df.iloc[-3*len(prediction_df):,1],truth_df.iloc[-3*len(prediction_df):,0],'-', label='Truth')\n",
    "            plt.plot_date(prediction_df.iloc[:,1],prediction_df.iloc[:,0],'-',label ='Prediction')\n",
    "            plt.legend()\n",
    "            plt.show();\n",
    "\n",
    "            iteration_end = time.monotonic()\n",
    "\n",
    "            predictions_descaled = np.where(predictions_descaled<0, 0, predictions_descaled)\n",
    "\n",
    "            mean_abs_SHAP_inst.append(mean_absolute_scaled_error(predictions_df['store_truth'].iloc[-(len(prediction_df)+1):],\n",
    "                                             predictions_df[f'store_pred_{N_HIDDEN}'],\n",
    "                                             truth_df.iloc[:-len(prediction_df),0]))\n",
    "\n",
    "            mean_sqr_SHAP_inst.append(mean_squared_error(predictions_df['store_truth'].iloc[-(len(prediction_df)+1):],\n",
    "                                             predictions_df[f'store_pred_{N_HIDDEN}'])**(1/2))\n",
    "\n",
    "            time_SHAP_inst.append(iteration_end - iteration_start)\n",
    "\n",
    "            hidden_dic['mase'] = mean_abs_SHAP_inst\n",
    "            hidden_dic['mse']  = mean_sqr_SHAP_inst\n",
    "            hidden_dic['time'] = time_SHAP_inst\n",
    "\n",
    "            print(SHAP_th)\n",
    "            print(N_HIDDEN)\n",
    "            print(hidden_dic)\n",
    "\n",
    "        #predictions_df.to_csv(f'{folder_path}/Rossmann_LSTM__SHAPins{SHAP_th}.csv')\n",
    "        SHAP_inst_dic[SHAP_th] = hidden_dic\n",
    "    %store SHAP_inst_dic\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "            dic = {}\n",
    "            dic[f'store_truth'] = Rossmann_df[TGT]\n",
    "            dic[f'store_truth_dates'] = full_dates\n",
    "            truth_df = pd.DataFrame.from_dict(dic)\n",
    "\n",
    "            dic= {}\n",
    "            dic[f'store_pred'] = predictions_descaled\n",
    "            dic[f'store_pred_dates'] = dates\n",
    "            prediction_df = pd.DataFrame.from_dict(dic)\n",
    "            prediction_df.to_csv(f'{folder_path}/Rossmann_LSTM_hidden{N_HIDDEN}.csv')\n",
    "\n",
    "            plt.plot_date(truth_df.iloc[-3*len(prediction_df):,1],truth_df.iloc[-3*len(prediction_df):,0],'-', label='Truth')\n",
    "            plt.plot_date(prediction_df.iloc[:,1],prediction_df.iloc[:,0],'-',label ='Prediction')\n",
    "            plt.legend()\n",
    "            plt.show();\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9576d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if SHAP_avrag == True:\n",
    "    folder_path = 'Predictions/grid_search_SHAP'\n",
    "\n",
    "    SHAP_avg_th = [0.01,0.02,0.03,0.04]\n",
    "    avg_LSTMSHAP= pd.read_csv('Predictions/Single_Run/Features_avg_LSTMSHAP.csv')\n",
    "    SHAP_avg_dic = {}\n",
    "\n",
    "\n",
    "    try:\n",
    "        os.mkdir(f'{folder_path}')\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    for SHAP_th in SHAP_avg_th:\n",
    "        mean_abs_SHAP_avg = []\n",
    "        mean_sqr_SHAP_avg = []\n",
    "        time_SHAP_avg = []\n",
    "\n",
    "        for N_HIDDEN in hidden_values:\n",
    "            torch.manual_seed(8)\n",
    "            np.random.seed(8)\n",
    "            pl.seed_everything(8);\n",
    "            iteration_start = time.monotonic()\n",
    "\n",
    "            hidden_dic = {}\n",
    "\n",
    "            class SalesPredictionModel(nn.Module):\n",
    "                def __init__(self, n_features, n_hidden = N_HIDDEN, n_layers = N_LAYERS):\n",
    "                    super().__init__()\n",
    "                    self.n_hidden = n_hidden\n",
    "\n",
    "                    self.lstm = nn.LSTM(\n",
    "                        input_size = n_features,\n",
    "                        hidden_size = n_hidden,\n",
    "                        batch_first = True,\n",
    "                        num_layers = n_layers,\n",
    "                        dropout = 0.2\n",
    "                    )\n",
    "                    self.regressor = nn.Linear(n_hidden,1)\n",
    "\n",
    "                def forward(self,x):\n",
    "                    self.lstm.flatten_parameters()\n",
    "\n",
    "                    _, (hidden, _) = self.lstm(x)\n",
    "                    out = hidden[-1]\n",
    "\n",
    "                    return self.regressor(out)\n",
    "\n",
    "\n",
    "            class SalesPredictor(pl.LightningModule):\n",
    "\n",
    "                def __init__(self, n_features: int):\n",
    "                    super().__init__()\n",
    "                    self.model=SalesPredictionModel(n_features)\n",
    "                    self.criterion = nn.MSELoss()\n",
    "\n",
    "                def forward(self, x, labels= None):\n",
    "                    output = self.model(x)\n",
    "                    loss = 0\n",
    "                    if labels is not None:\n",
    "                        loss = self.criterion(output, labels.unsqueeze(dim=1))\n",
    "                    return loss, output\n",
    "\n",
    "                def training_step(self, batch, batch_index):\n",
    "                    sequences = batch['sequence']\n",
    "                    labels = batch['label']\n",
    "\n",
    "                    loss, outputs = self(sequences, labels)\n",
    "                    self.log('train_loss', loss, prog_bar = True, logger=False)\n",
    "                    return loss\n",
    "\n",
    "                def validation_step(self, batch, batch_index):\n",
    "                    sequences = batch['sequence']\n",
    "                    labels = batch['label']\n",
    "\n",
    "                    loss, outputs = self(sequences, labels)\n",
    "                    self.log('val_loss', loss, prog_bar = True, logger=False)\n",
    "                    return loss\n",
    "\n",
    "                def test_step(self, batch, batch_index):\n",
    "                    sequences = batch['sequence']\n",
    "                    labels = batch['label']\n",
    "\n",
    "                    loss, outputs = self(sequences, labels)\n",
    "                    self.log('test_loss', loss, prog_bar = True, logger=False)\n",
    "                    return loss\n",
    "\n",
    "                def configure_optimizers(self):\n",
    "                    return optim.AdamW(self.parameters(), lr = LEARNING)\n",
    "\n",
    "\n",
    "            #makes SHAP calculations for all stores inside the rossmann_treated dataset if removed the [:1]\n",
    "\n",
    "            #to omit outputs\n",
    "            #with io.capture_output() as captured:\n",
    "            df = Rossmann_df.drop(columns  = 'Date')\n",
    "            features = list(avg_LSTMSHAP['feature_name'].loc[avg_LSTMSHAP['shap_value'] > SHAP_th])\n",
    "\n",
    "            #return all columns names ('features') except for customers, since it's not an available \n",
    "            #information for future points\n",
    "            features_df = features_dataframe(df,features) \n",
    "            #returns dataframe with the features to be analised\n",
    "\n",
    "            #split into test and train and minmaxscaler\n",
    "            train_df, test_df, train_size =  train_test_spliter(105,features_df)\n",
    "            train_df, test_df, scaler = data_scaler(train_df,test_df)\n",
    "            #make sequences with the data\n",
    "            train_sequences = create_sequences(train_df,TGT,SEQUENCE_LENGTH)\n",
    "            test_sequences = create_sequences (test_df,TGT,SEQUENCE_LENGTH)\n",
    "\n",
    "            #trains the model and store the most recent checkpoints removing previous ones if existing\n",
    "            data_module = SalesDataModule(train_sequences, test_sequences, batch_size = BATCH_SIZE)\n",
    "            data_module.setup()\n",
    "            train_dataset = Dataset(train_sequences)\n",
    "            test_dataset = Dataset(test_sequences)\n",
    "            model = SalesPredictor(n_features = train_df.shape[1])\n",
    "\n",
    "\n",
    "\n",
    "            try:\n",
    "                os.remove(f\"{folder_path}/Checkpoints/Rossmann_LSTM_hidden{N_HIDDEN}_SHAPavg{SHAP_th}.ckpt\")\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            checkpoint_callback = ModelCheckpoint(\n",
    "                dirpath = f'{folder_path}/Checkpoints',\n",
    "                filename = f'Rossmann_LSTM_hidden{N_HIDDEN}_SHAPavg{SHAP_th}',\n",
    "                save_top_k = 1,\n",
    "                verbose = False ,\n",
    "                monitor = 'val_loss',\n",
    "                mode = 'min'\n",
    "            )\n",
    "            logger = TensorBoardLogger('lightning_logs', name = 'btc-price')\n",
    "            early_stopping_callback = EarlyStopping(monitor= 'val_loss', patience = PATIENCE)\n",
    "            trainer = pl.Trainer(\n",
    "                logger = logger,\n",
    "                callbacks=[early_stopping_callback, checkpoint_callback],\n",
    "                max_epochs = N_EPOCHS,\n",
    "                gpus = 0,\n",
    "            )\n",
    "            trainer.fit(model, data_module)\n",
    "\n",
    "            #load the best model from checkpoint\n",
    "            trained_model = SalesPredictor.load_from_checkpoint(\n",
    "            f'{folder_path}/Checkpoints/Rossmann_LSTM_hidden{N_HIDDEN}_SHAPavg{SHAP_th}.ckpt',\n",
    "            n_features = train_df.shape[1]\n",
    "            )\n",
    "\n",
    "            predictions = []\n",
    "            labels = []\n",
    "\n",
    "            for item in test_dataset:\n",
    "                sequence = item['sequence']\n",
    "                label = item['label']\n",
    "\n",
    "                if len(predictions) > SEQUENCE_LENGTH:\n",
    "                    for j in range(SEQUENCE_LENGTH):\n",
    "                        sequence[-SEQUENCE_LENGTH+j,0] = float(predictions[-SEQUENCE_LENGTH+j])\n",
    "                else: \n",
    "                    for j in range(len(predictions)):\n",
    "                        sequence[-len(predictions)+j,0] = float(predictions[-len(predictions)+j])\n",
    "\n",
    "                _,output = trained_model(sequence.unsqueeze(dim=0))\n",
    "                predictions.append(output.item())\n",
    "                labels.append(label.item())\n",
    "\n",
    "\n",
    "\n",
    "            descaler = MinMaxScaler()\n",
    "            descaler.min_, descaler.scale_ = scaler.min_[0], scaler.scale_[0]\n",
    "\n",
    "            predictions_descaled = descale(descaler,predictions)\n",
    "            labels_descaled = descale(descaler,labels)\n",
    "\n",
    "            test_data = df[train_size+1:]\n",
    "            test_sequences_data = test_data.iloc[SEQUENCE_LENGTH:]\n",
    "\n",
    "            dates = matplotlib.dates.date2num(Rossmann_df.iloc[-len(predictions_descaled):].Date.tolist())\n",
    "            full_dates = matplotlib.dates.date2num(Rossmann_df.Date.tolist())\n",
    "\n",
    "            dic= {}\n",
    "            dic[f'store_pred_{N_HIDDEN}'] = predictions_descaled\n",
    "            pred_df = pd.DataFrame.from_dict(dic)\n",
    "            pred_df = pred_df.shift(-1)\n",
    "\n",
    "\n",
    "            dic = {}\n",
    "            dic[f'store_pred_dates'] = dates\n",
    "            dic[f'store_truth'] = Rossmann_df[TGT].iloc[-len(pred_df):]\n",
    "            truth_df = pd.DataFrame.from_dict(dic)\n",
    "\n",
    "            if N_HIDDEN != hidden_values[0]:\n",
    "                predictions_df = predictions_df.join(pred_df, how = 'left')\n",
    "            else:\n",
    "                truth_df.reset_index(inplace = True)\n",
    "                truth_df.drop('index', axis=1)\n",
    "                predictions_df = truth_df\n",
    "                predictions_df = predictions_df.join(pred_df, how = 'left')\n",
    "                predictions_df = predictions_df.iloc[:-1]\n",
    "\n",
    "            display(predictions_df)\n",
    "\n",
    "            dic = {}\n",
    "            dic[f'store_truth'] = Rossmann_df[TGT]\n",
    "            dic[f'store_truth_dates'] = full_dates\n",
    "            truth_df = pd.DataFrame.from_dict(dic)\n",
    "\n",
    "            dic= {}\n",
    "            dic[f'store_pred'] = predictions_descaled\n",
    "            dic[f'store_pred_dates'] = dates\n",
    "            prediction_df = pd.DataFrame.from_dict(dic)\n",
    "            prediction_df['store_pred'] =prediction_df['store_pred'].shift(-1)\n",
    "\n",
    "            plt.figure(figsize=(21, 7))\n",
    "            plt.plot_date(truth_df.iloc[-3*len(prediction_df):,1],truth_df.iloc[-3*len(prediction_df):,0],'-', label='Truth')\n",
    "            plt.plot_date(prediction_df.iloc[:,1],prediction_df.iloc[:,0],'-',label ='Prediction')\n",
    "            plt.legend()\n",
    "            plt.show();\n",
    "\n",
    "            iteration_end = time.monotonic()\n",
    "\n",
    "            predictions_descaled = np.where(predictions_descaled<0, 0, predictions_descaled)\n",
    "\n",
    "            mean_abs_SHAP_avg.append(mean_absolute_scaled_error(predictions_df['store_truth'].iloc[-(len(prediction_df)+1):],\n",
    "                                             predictions_df[f'store_pred_{N_HIDDEN}'],\n",
    "                                             truth_df.iloc[:-len(prediction_df),0]))\n",
    "\n",
    "            mean_sqr_SHAP_avg.append(mean_squared_error(predictions_df['store_truth'].iloc[-(len(prediction_df)+1):],\n",
    "                                             predictions_df[f'store_pred_{N_HIDDEN}'])**(1/2))\n",
    "\n",
    "            time_SHAP_avg.append(iteration_end - iteration_start)\n",
    "\n",
    "            hidden_dic['mase'] = mean_abs_SHAP_avg\n",
    "            hidden_dic['mse']  = mean_sqr_SHAP_avg\n",
    "            hidden_dic['time'] = time_SHAP_avg\n",
    "\n",
    "            print(SHAP_th)\n",
    "            print(N_HIDDEN)\n",
    "            print(hidden_dic)\n",
    "\n",
    "        #predictions_df.to_csv(f'{folder_path}/Rossmann_LSTM_SHAPavg{SHAP_th}.csv')\n",
    "        SHAP_avg_dic[SHAP_th] = hidden_dic\n",
    "    %store SHAP_avg_dic\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "            dic = {}\n",
    "            dic[f'store_truth'] = Rossmann_df[TGT]\n",
    "            dic[f'store_truth_dates'] = full_dates\n",
    "            truth_df = pd.DataFrame.from_dict(dic)\n",
    "\n",
    "            dic= {}\n",
    "            dic[f'store_pred'] = predictions_descaled\n",
    "            dic[f'store_pred_dates'] = dates\n",
    "            prediction_df = pd.DataFrame.from_dict(dic)\n",
    "            prediction_df.to_csv(f'{folder_path}/Rossmann_LSTM_hidden{N_HIDDEN}.csv')\n",
    "\n",
    "            plt.plot_date(truth_df.iloc[-3*len(prediction_df):,1],truth_df.iloc[-3*len(prediction_df):,0],'-', label='Truth')\n",
    "            plt.plot_date(prediction_df.iloc[:,1],prediction_df.iloc[:,0],'-',label ='Prediction')\n",
    "            plt.legend()\n",
    "            plt.show();\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8295dc8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMV_Full = True\n",
    "if IMV_Full == True:\n",
    "\n",
    "    IMV_Full_feats=pd.read_csv(f\"Predictions/Single_Run/Features_IMV_Full.csv\")\n",
    "    \n",
    "    folder_path = 'Predictions/grid_search_IMVF'\n",
    "    \n",
    "    features = list(IMV_Full_feats['features'].loc[IMV_Full_feats['Importance'] > 0.06])\n",
    "    \n",
    "    try:\n",
    "        os.mkdir(f'{folder_path}')\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    mean_abs_IMV_Full = []\n",
    "    mean_sqr_IMV_Full = []\n",
    "    time_IMV_Full = []\n",
    "    \n",
    "    for N_HIDDEN in hidden_values:\n",
    "        torch.manual_seed(8)\n",
    "        np.random.seed(8)\n",
    "        pl.seed_everything(8);\n",
    "        iteration_start = time.monotonic()\n",
    "\n",
    "        class SalesPredictionModel(nn.Module):\n",
    "            def __init__(self, n_features, n_hidden = N_HIDDEN, n_layers = N_LAYERS):\n",
    "                super().__init__()\n",
    "                self.n_hidden = n_hidden\n",
    "\n",
    "                self.lstm = nn.LSTM(\n",
    "                    input_size = n_features,\n",
    "                    hidden_size = n_hidden,\n",
    "                    batch_first = True,\n",
    "                    num_layers = n_layers,\n",
    "                    dropout = 0.2\n",
    "                )\n",
    "                self.regressor = nn.Linear(n_hidden,1)\n",
    "\n",
    "            def forward(self,x):\n",
    "                self.lstm.flatten_parameters()\n",
    "\n",
    "                _, (hidden, _) = self.lstm(x)\n",
    "                out = hidden[-1]\n",
    "\n",
    "                return self.regressor(out)\n",
    "\n",
    "\n",
    "        class SalesPredictor(pl.LightningModule):\n",
    "\n",
    "            def __init__(self, n_features: int):\n",
    "                super().__init__()\n",
    "                self.model=SalesPredictionModel(n_features)\n",
    "                self.criterion = nn.MSELoss()\n",
    "\n",
    "            def forward(self, x, labels= None):\n",
    "                output = self.model(x)\n",
    "                loss = 0\n",
    "                if labels is not None:\n",
    "                    loss = self.criterion(output, labels.unsqueeze(dim=1))\n",
    "                return loss, output\n",
    "\n",
    "            def training_step(self, batch, batch_index):\n",
    "                sequences = batch['sequence']\n",
    "                labels = batch['label']\n",
    "\n",
    "                loss, outputs = self(sequences, labels)\n",
    "                self.log('train_loss', loss, prog_bar = True, logger=False)\n",
    "                return loss\n",
    "\n",
    "            def validation_step(self, batch, batch_index):\n",
    "                sequences = batch['sequence']\n",
    "                labels = batch['label']\n",
    "\n",
    "                loss, outputs = self(sequences, labels)\n",
    "                self.log('val_loss', loss, prog_bar = True, logger=False)\n",
    "                return loss\n",
    "\n",
    "            def test_step(self, batch, batch_index):\n",
    "                sequences = batch['sequence']\n",
    "                labels = batch['label']\n",
    "\n",
    "                loss, outputs = self(sequences, labels)\n",
    "                self.log('test_loss', loss, prog_bar = True, logger=False)\n",
    "                return loss\n",
    "\n",
    "            def configure_optimizers(self):\n",
    "                return optim.AdamW(self.parameters(), lr = LEARNING)\n",
    "\n",
    "\n",
    "        #makes SHAP calculations for all stores inside the rossmann_treated dataset if removed the [:1]\n",
    "\n",
    "        #to omit outputs\n",
    "        #with io.capture_output() as captured:\n",
    "        df = Rossmann_df.drop(columns  = 'Date')\n",
    "        \n",
    "        #return all columns names ('features') except for customers, since it's not an available \n",
    "        #information for future points\n",
    "        features_df = features_dataframe(df,features) \n",
    "        #returns dataframe with the features to be analised\n",
    "\n",
    "        #split into test and train and minmaxscaler\n",
    "        train_df, test_df, train_size =  train_test_spliter(105,features_df)\n",
    "        train_df, test_df, scaler = data_scaler(train_df,test_df)\n",
    "        #make sequences with the data\n",
    "        train_sequences = create_sequences(train_df,TGT,SEQUENCE_LENGTH)\n",
    "        test_sequences = create_sequences (test_df,TGT,SEQUENCE_LENGTH)\n",
    "\n",
    "        #trains the model and store the most recent checkpoints removing previous ones if existing\n",
    "        data_module = SalesDataModule(train_sequences, test_sequences, batch_size = BATCH_SIZE)\n",
    "        data_module.setup()\n",
    "        train_dataset = Dataset(train_sequences)\n",
    "        test_dataset = Dataset(test_sequences)\n",
    "        model = SalesPredictor(n_features = train_df.shape[1])\n",
    "\n",
    "\n",
    "\n",
    "        try:\n",
    "            os.remove(f\"{folder_path}/Checkpoints/Rossmann_LSTM_hidden{N_HIDDEN}.ckpt\")\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        checkpoint_callback = ModelCheckpoint(\n",
    "            dirpath = f'{folder_path}/Checkpoints',\n",
    "            filename = f'Rossmann_LSTM_hidden{N_HIDDEN}',\n",
    "            save_top_k = 1,\n",
    "            verbose = False ,\n",
    "            monitor = 'val_loss',\n",
    "            mode = 'min'\n",
    "        )\n",
    "        logger = TensorBoardLogger('lightning_logs', name = 'btc-price')\n",
    "        early_stopping_callback = EarlyStopping(monitor= 'val_loss', patience = PATIENCE)\n",
    "        trainer = pl.Trainer(\n",
    "            logger = logger,\n",
    "            callbacks=[early_stopping_callback, checkpoint_callback],\n",
    "            max_epochs = N_EPOCHS,\n",
    "            gpus = 0,\n",
    "        )\n",
    "        trainer.fit(model, data_module)\n",
    "\n",
    "        #load the best model from checkpoint\n",
    "        trained_model = SalesPredictor.load_from_checkpoint(\n",
    "        f'{folder_path}/Checkpoints/Rossmann_LSTM_hidden{N_HIDDEN}.ckpt',\n",
    "        n_features = train_df.shape[1]\n",
    "        )\n",
    "\n",
    "        predictions = []\n",
    "        labels = []\n",
    "\n",
    "        for item in test_dataset:\n",
    "            sequence = item['sequence']\n",
    "            label = item['label']\n",
    "\n",
    "            if len(predictions) > SEQUENCE_LENGTH:\n",
    "                for j in range(SEQUENCE_LENGTH):\n",
    "                    sequence[-SEQUENCE_LENGTH+j,0] = float(predictions[-SEQUENCE_LENGTH+j])\n",
    "            else: \n",
    "                for j in range(len(predictions)):\n",
    "                    sequence[-len(predictions)+j,0] = float(predictions[-len(predictions)+j])\n",
    "\n",
    "            _,output = trained_model(sequence.unsqueeze(dim=0))\n",
    "            predictions.append(output.item())\n",
    "            labels.append(label.item())\n",
    "\n",
    "\n",
    "\n",
    "        descaler = MinMaxScaler()\n",
    "        descaler.min_, descaler.scale_ = scaler.min_[0], scaler.scale_[0]\n",
    "\n",
    "        predictions_descaled = descale(descaler,predictions)\n",
    "        labels_descaled = descale(descaler,labels)\n",
    "\n",
    "        test_data = df[train_size+1:]\n",
    "        test_sequences_data = test_data.iloc[SEQUENCE_LENGTH:]\n",
    "\n",
    "        dates = matplotlib.dates.date2num(Rossmann_df.iloc[-len(predictions_descaled):].Date.tolist())\n",
    "        full_dates = matplotlib.dates.date2num(Rossmann_df.Date.tolist())\n",
    "\n",
    "        predictions_descaled = np.where(predictions_descaled<0, 0, predictions_descaled)\n",
    "        \n",
    "        dic= {}\n",
    "        dic[f'store_pred_{N_HIDDEN}'] = predictions_descaled\n",
    "        pred_df = pd.DataFrame.from_dict(dic)\n",
    "        pred_df = pred_df.shift(-1)\n",
    "\n",
    "\n",
    "        dic = {}\n",
    "        dic[f'store_pred_dates'] = dates\n",
    "        dic[f'store_truth'] = Rossmann_df[TGT].iloc[-len(pred_df):]\n",
    "        truth_df = pd.DataFrame.from_dict(dic)\n",
    "\n",
    "\n",
    "        if N_HIDDEN != hidden_values[0]:\n",
    "            predictions_df = predictions_df.join(pred_df, how = 'left')\n",
    "        else:\n",
    "            truth_df.reset_index(inplace = True)\n",
    "            truth_df.drop('index', axis=1)\n",
    "            predictions_df = truth_df\n",
    "            predictions_df = predictions_df.join(pred_df, how = 'left')\n",
    "            predictions_df = predictions_df.iloc[:-1]\n",
    "\n",
    "        #display(predictions_df)\n",
    "        \n",
    "        dic = {}\n",
    "        dic[f'store_truth'] = Rossmann_df[TGT]\n",
    "        dic[f'store_truth_dates'] = full_dates\n",
    "        truth_df = pd.DataFrame.from_dict(dic)\n",
    "\n",
    "        dic= {}\n",
    "        dic[f'store_pred'] = predictions_descaled\n",
    "        dic[f'store_pred_dates'] = dates\n",
    "        prediction_df = pd.DataFrame.from_dict(dic)\n",
    "        prediction_df['store_pred'] =prediction_df['store_pred'].shift(-1)\n",
    "        \n",
    "        plt.figure(figsize=(21, 7))\n",
    "        plt.plot_date(truth_df.iloc[-3*len(prediction_df):,1],truth_df.iloc[-3*len(prediction_df):,0],'-', label='Truth')\n",
    "        plt.plot_date(prediction_df.iloc[:,1],prediction_df.iloc[:,0],'-',label ='Prediction')\n",
    "        plt.legend()\n",
    "        plt.show();\n",
    "    \n",
    "    \n",
    "    \n",
    "        print('mean absolute scaled error: ')\n",
    "        print(mean_absolute_scaled_error(predictions_df['store_truth'].iloc[-(len(prediction_df)+1):],\n",
    "                                         predictions_df[f'store_pred_{N_HIDDEN}'],\n",
    "                                         truth_df.iloc[:-len(prediction_df),0]))\n",
    "        print('\\n','mean squared error: ')\n",
    "        print(mean_squared_error(predictions_df['store_truth'].iloc[-(len(prediction_df)+1):],\n",
    "                                         predictions_df[f'store_pred_{N_HIDDEN}']))\n",
    "        print('\\n','root mean squared error: ')\n",
    "        print((mean_squared_error(predictions_df['store_truth'].iloc[-(len(prediction_df)+1):],\n",
    "                                         predictions_df[f'store_pred_{N_HIDDEN}']))**(1/2)) \n",
    "\n",
    "        iteration_end = time.monotonic()\n",
    "        print('\\n',\"Iteration time: \", iteration_end - iteration_start)\n",
    "\n",
    "        mean_abs_IMV_Full.append(mean_absolute_scaled_error(predictions_df['store_truth'].iloc[-(len(prediction_df)+1):],\n",
    "                                         predictions_df[f'store_pred_{N_HIDDEN}'],\n",
    "                                         truth_df.iloc[:-len(prediction_df),0]))\n",
    "\n",
    "        mean_sqr_IMV_Full.append(mean_squared_error(predictions_df['store_truth'].iloc[-(len(prediction_df)+1):],\n",
    "                                         predictions_df[f'store_pred_{N_HIDDEN}'])**(1/2))\n",
    "\n",
    "        time_IMV_Full.append(iteration_end - iteration_start)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f88bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMV_Tensor = True\n",
    "if IMV_Tensor == True:\n",
    "\n",
    "    IMV_Tensor_feats=pd.read_csv(f\"Predictions/Single_Run/Features_IMV_Tensor.csv\")\n",
    "    \n",
    "    folder_path = 'Predictions/grid_search_IMVF'\n",
    "    \n",
    "    features = list(IMV_Tensor_feats['features'].loc[IMV_Tensor_feats['Importance'] > 0.045])\n",
    "    \n",
    "    try:\n",
    "        os.mkdir(f'{folder_path}')\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    mean_abs_IMV_Tensor = []\n",
    "    mean_sqr_IMV_Tensor = []\n",
    "    time_IMV_Tensor = []\n",
    "    \n",
    "    for N_HIDDEN in hidden_values:\n",
    "        torch.manual_seed(8)\n",
    "        np.random.seed(8)\n",
    "        pl.seed_everything(8);\n",
    "        iteration_start = time.monotonic()\n",
    "\n",
    "        class SalesPredictionModel(nn.Module):\n",
    "            def __init__(self, n_features, n_hidden = N_HIDDEN, n_layers = N_LAYERS):\n",
    "                super().__init__()\n",
    "                self.n_hidden = n_hidden\n",
    "\n",
    "                self.lstm = nn.LSTM(\n",
    "                    input_size = n_features,\n",
    "                    hidden_size = n_hidden,\n",
    "                    batch_first = True,\n",
    "                    num_layers = n_layers,\n",
    "                    dropout = 0.2\n",
    "                )\n",
    "                self.regressor = nn.Linear(n_hidden,1)\n",
    "\n",
    "            def forward(self,x):\n",
    "                self.lstm.flatten_parameters()\n",
    "\n",
    "                _, (hidden, _) = self.lstm(x)\n",
    "                out = hidden[-1]\n",
    "\n",
    "                return self.regressor(out)\n",
    "\n",
    "\n",
    "        class SalesPredictor(pl.LightningModule):\n",
    "\n",
    "            def __init__(self, n_features: int):\n",
    "                super().__init__()\n",
    "                self.model=SalesPredictionModel(n_features)\n",
    "                self.criterion = nn.MSELoss()\n",
    "\n",
    "            def forward(self, x, labels= None):\n",
    "                output = self.model(x)\n",
    "                loss = 0\n",
    "                if labels is not None:\n",
    "                    loss = self.criterion(output, labels.unsqueeze(dim=1))\n",
    "                return loss, output\n",
    "\n",
    "            def training_step(self, batch, batch_index):\n",
    "                sequences = batch['sequence']\n",
    "                labels = batch['label']\n",
    "\n",
    "                loss, outputs = self(sequences, labels)\n",
    "                self.log('train_loss', loss, prog_bar = True, logger=False)\n",
    "                return loss\n",
    "\n",
    "            def validation_step(self, batch, batch_index):\n",
    "                sequences = batch['sequence']\n",
    "                labels = batch['label']\n",
    "\n",
    "                loss, outputs = self(sequences, labels)\n",
    "                self.log('val_loss', loss, prog_bar = True, logger=False)\n",
    "                return loss\n",
    "\n",
    "            def test_step(self, batch, batch_index):\n",
    "                sequences = batch['sequence']\n",
    "                labels = batch['label']\n",
    "\n",
    "                loss, outputs = self(sequences, labels)\n",
    "                self.log('test_loss', loss, prog_bar = True, logger=False)\n",
    "                return loss\n",
    "\n",
    "            def configure_optimizers(self):\n",
    "                return optim.AdamW(self.parameters(), lr = LEARNING)\n",
    "\n",
    "\n",
    "        #makes SHAP calculations for all stores inside the rossmann_treated dataset if removed the [:1]\n",
    "\n",
    "        #to omit outputs\n",
    "        #with io.capture_output() as captured:\n",
    "        df = Rossmann_df.drop(columns  = 'Date')\n",
    "        \n",
    "        #return all columns names ('features') except for customers, since it's not an available \n",
    "        #information for future points\n",
    "        features_df = features_dataframe(df,features) \n",
    "        #returns dataframe with the features to be analised\n",
    "\n",
    "        #split into test and train and minmaxscaler\n",
    "        train_df, test_df, train_size =  train_test_spliter(105,features_df)\n",
    "        train_df, test_df, scaler = data_scaler(train_df,test_df)\n",
    "        #make sequences with the data\n",
    "        train_sequences = create_sequences(train_df,TGT,SEQUENCE_LENGTH)\n",
    "        test_sequences = create_sequences (test_df,TGT,SEQUENCE_LENGTH)\n",
    "\n",
    "        #trains the model and store the most recent checkpoints removing previous ones if existing\n",
    "        data_module = SalesDataModule(train_sequences, test_sequences, batch_size = BATCH_SIZE)\n",
    "        data_module.setup()\n",
    "        train_dataset = Dataset(train_sequences)\n",
    "        test_dataset = Dataset(test_sequences)\n",
    "        model = SalesPredictor(n_features = train_df.shape[1])\n",
    "\n",
    "\n",
    "\n",
    "        try:\n",
    "            os.remove(f\"{folder_path}/Checkpoints/Rossmann_LSTM_hidden{N_HIDDEN}.ckpt\")\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        checkpoint_callback = ModelCheckpoint(\n",
    "            dirpath = f'{folder_path}/Checkpoints',\n",
    "            filename = f'Rossmann_LSTM_hidden{N_HIDDEN}',\n",
    "            save_top_k = 1,\n",
    "            verbose = False ,\n",
    "            monitor = 'val_loss',\n",
    "            mode = 'min'\n",
    "        )\n",
    "        logger = TensorBoardLogger('lightning_logs', name = 'btc-price')\n",
    "        early_stopping_callback = EarlyStopping(monitor= 'val_loss', patience = PATIENCE)\n",
    "        trainer = pl.Trainer(\n",
    "            logger = logger,\n",
    "            callbacks=[early_stopping_callback, checkpoint_callback],\n",
    "            max_epochs = N_EPOCHS,\n",
    "            gpus = 0,\n",
    "        )\n",
    "        trainer.fit(model, data_module)\n",
    "\n",
    "        #load the best model from checkpoint\n",
    "        trained_model = SalesPredictor.load_from_checkpoint(\n",
    "        f'{folder_path}/Checkpoints/Rossmann_LSTM_hidden{N_HIDDEN}.ckpt',\n",
    "        n_features = train_df.shape[1]\n",
    "        )\n",
    "\n",
    "        predictions = []\n",
    "        labels = []\n",
    "\n",
    "        for item in test_dataset:\n",
    "            sequence = item['sequence']\n",
    "            label = item['label']\n",
    "\n",
    "            if len(predictions) > SEQUENCE_LENGTH:\n",
    "                for j in range(SEQUENCE_LENGTH):\n",
    "                    sequence[-SEQUENCE_LENGTH+j,0] = float(predictions[-SEQUENCE_LENGTH+j])\n",
    "            else: \n",
    "                for j in range(len(predictions)):\n",
    "                    sequence[-len(predictions)+j,0] = float(predictions[-len(predictions)+j])\n",
    "\n",
    "            _,output = trained_model(sequence.unsqueeze(dim=0))\n",
    "            predictions.append(output.item())\n",
    "            labels.append(label.item())\n",
    "\n",
    "\n",
    "\n",
    "        descaler = MinMaxScaler()\n",
    "        descaler.min_, descaler.scale_ = scaler.min_[0], scaler.scale_[0]\n",
    "\n",
    "        predictions_descaled = descale(descaler,predictions)\n",
    "        labels_descaled = descale(descaler,labels)\n",
    "\n",
    "        test_data = df[train_size+1:]\n",
    "        test_sequences_data = test_data.iloc[SEQUENCE_LENGTH:]\n",
    "\n",
    "        dates = matplotlib.dates.date2num(Rossmann_df.iloc[-len(predictions_descaled):].Date.tolist())\n",
    "        full_dates = matplotlib.dates.date2num(Rossmann_df.Date.tolist())\n",
    "\n",
    "        predictions_descaled = np.where(predictions_descaled<0, 0, predictions_descaled)\n",
    "        \n",
    "        dic= {}\n",
    "        dic[f'store_pred_{N_HIDDEN}'] = predictions_descaled\n",
    "        pred_df = pd.DataFrame.from_dict(dic)\n",
    "        pred_df = pred_df.shift(-1)\n",
    "\n",
    "\n",
    "        dic = {}\n",
    "        dic[f'store_pred_dates'] = dates\n",
    "        dic[f'store_truth'] = Rossmann_df[TGT].iloc[-len(pred_df):]\n",
    "        truth_df = pd.DataFrame.from_dict(dic)\n",
    "\n",
    "\n",
    "        if N_HIDDEN != hidden_values[0]:\n",
    "            predictions_df = predictions_df.join(pred_df, how = 'left')\n",
    "        else:\n",
    "            truth_df.reset_index(inplace = True)\n",
    "            truth_df.drop('index', axis=1)\n",
    "            predictions_df = truth_df\n",
    "            predictions_df = predictions_df.join(pred_df, how = 'left')\n",
    "            predictions_df = predictions_df.iloc[:-1]\n",
    "\n",
    "        #display(predictions_df)\n",
    "        \n",
    "        dic = {}\n",
    "        dic[f'store_truth'] = Rossmann_df[TGT]\n",
    "        dic[f'store_truth_dates'] = full_dates\n",
    "        truth_df = pd.DataFrame.from_dict(dic)\n",
    "\n",
    "        dic= {}\n",
    "        dic[f'store_pred'] = predictions_descaled\n",
    "        dic[f'store_pred_dates'] = dates\n",
    "        prediction_df = pd.DataFrame.from_dict(dic)\n",
    "        prediction_df['store_pred'] =prediction_df['store_pred'].shift(-1)\n",
    "        \n",
    "        plt.figure(figsize=(21, 7))\n",
    "        plt.plot_date(truth_df.iloc[-3*len(prediction_df):,1],truth_df.iloc[-3*len(prediction_df):,0],'-', label='Truth')\n",
    "        plt.plot_date(prediction_df.iloc[:,1],prediction_df.iloc[:,0],'-',label ='Prediction')\n",
    "        plt.legend()\n",
    "        plt.show();\n",
    "        \n",
    "        print('mean absolute scaled error: ')\n",
    "        print(mean_absolute_scaled_error(predictions_df['store_truth'].iloc[-(len(prediction_df)+1):],\n",
    "                                         predictions_df[f'store_pred_{N_HIDDEN}'],\n",
    "                                         truth_df.iloc[:-len(prediction_df),0]))\n",
    "        print('\\n','mean squared error: ')\n",
    "        print(mean_squared_error(predictions_df['store_truth'].iloc[-(len(prediction_df)+1):],\n",
    "                                         predictions_df[f'store_pred_{N_HIDDEN}']))\n",
    "        print('\\n','root mean squared error: ')\n",
    "        print((mean_squared_error(predictions_df['store_truth'].iloc[-(len(prediction_df)+1):],\n",
    "                                         predictions_df[f'store_pred_{N_HIDDEN}']))**(1/2)) \n",
    "\n",
    "        iteration_end = time.monotonic()\n",
    "        print('\\n',\"Iteration time: \", iteration_end - iteration_start)\n",
    "\n",
    "        mean_abs_IMV_Tensor.append(mean_absolute_scaled_error(predictions_df['store_truth'].iloc[-(len(prediction_df)+1):],\n",
    "                                         predictions_df[f'store_pred_{N_HIDDEN}'],\n",
    "                                         truth_df.iloc[:-len(prediction_df),0]))\n",
    "\n",
    "        mean_sqr_IMV_Tensor.append(mean_squared_error(predictions_df['store_truth'].iloc[-(len(prediction_df)+1):],\n",
    "                                         predictions_df[f'store_pred_{N_HIDDEN}'])**(1/2))\n",
    "\n",
    "        time_IMV_Tensor.append(iteration_end - iteration_start)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9df37f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
